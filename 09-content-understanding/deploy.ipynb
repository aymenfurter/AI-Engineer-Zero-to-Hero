{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163c1dd8",
   "metadata": {},
   "source": [
    "# Lab 9: Content Understanding\n",
    "\n",
    "**Azure AI Content Understanding** extracts structured data from multimodal content using prebuilt analyzers:\n",
    "\n",
    "| Content Type | Analyzer | Output |\n",
    "|-------------|----------|--------|\n",
    "| Documents | `prebuilt-layout` | Text, tables, structure as markdown |\n",
    "| Images | `prebuilt-imageSearch` | Descriptions, object detection |\n",
    "| Video | `prebuilt-videoSearch` | Keyframes, transcripts, segments |\n",
    "\n",
    "> ‚ö†Ô∏è Requires GPT-4.1, GPT-4.1-mini, and text-embedding-3-large deployed in the same resource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402e384",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12feb191",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests azure-identity azure-ai-projects pandas ijson pypdf -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304cbb7",
   "metadata": {},
   "source": [
    "## Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os, json, time, requests, base64, re\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "RG = \"content-understanding-lab-rg\"\n",
    "LOCATION = \"swedencentral\"\n",
    "HUB_RG = \"foundry-lz-parent\"\n",
    "CU_API_VERSION = \"2025-11-01\"\n",
    "\n",
    "# Load .env files\n",
    "for env_path in [Path(\"../.env\"), Path(\".env\")]:\n",
    "    if env_path.exists():\n",
    "        for line in env_path.read_text().splitlines():\n",
    "            if '=' in line and not line.startswith('#'):\n",
    "                k, v = line.split('=', 1)\n",
    "                os.environ[k.strip()] = v.strip()\n",
    "\n",
    "APIM_URL = os.environ.get(\"APIM_URL\", \"\")\n",
    "APIM_KEY = os.environ.get(\"APIM_KEY\", \"\")\n",
    "APIM_NAME = re.match(r'https://([^.]+)\\.', APIM_URL).group(1) if APIM_URL else \"\"\n",
    "PRINCIPAL_ID = subprocess.run('az ad signed-in-user show --query id -o tsv', shell=True, capture_output=True, text=True).stdout.strip()\n",
    "\n",
    "print(f\"Resource Group: {RG} | Location: {LOCATION}\")\n",
    "print(f\"Principal ID: {PRINCIPAL_ID[:20]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba06ef65",
   "metadata": {},
   "source": [
    "## Step 3: Deploy Infrastructure (~5-7 min)\n",
    "Deploys AI Services with CU capability + required model deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2161c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!az group create -n \"{RG}\" -l \"{LOCATION}\" -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db480fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy spoke infrastructure with Content Understanding models\n",
    "deploy_cmd = f'''az deployment group create -g \"{RG}\" --template-file spoke.bicep \\\n",
    "    -p deployerPrincipalId=\"{PRINCIPAL_ID}\" \\\n",
    "    -p hubResourceGroup=\"{HUB_RG}\" \\\n",
    "    -p apimName=\"{APIM_NAME}\" \\\n",
    "    -p apimSubscriptionKey=\"{APIM_KEY}\" \\\n",
    "    -o table'''\n",
    "\n",
    "!{deploy_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53afbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(f'az deployment group show -g \"{RG}\" -n spoke --query properties.outputs -o json', shell=True, capture_output=True, text=True)\n",
    "if result.returncode != 0: raise Exception(f\"Deployment failed: {result.stderr}\")\n",
    "\n",
    "outputs = json.loads(result.stdout)\n",
    "CU_ENDPOINT = outputs['contentUnderstandingEndpoint']['value']\n",
    "GPT41_DEPLOYMENT = outputs['gpt41Deployment']['value']\n",
    "GPT41_MINI_DEPLOYMENT = outputs['gpt41MiniDeployment']['value']\n",
    "EMBEDDING_DEPLOYMENT = outputs['embeddingDeployment']['value']\n",
    "\n",
    "print(f\"‚úÖ CU Endpoint: {CU_ENDPOINT}\")\n",
    "print(f\"   Models: {GPT41_DEPLOYMENT}, {GPT41_MINI_DEPLOYMENT}, {EMBEDDING_DEPLOYMENT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7aba3",
   "metadata": {},
   "source": [
    "## Step 4: Configure CU Model Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cd177",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚è≥ Waiting for RBAC propagation (30s)...\")\n",
    "time.sleep(30)\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "get_cu_token = lambda: credential.get_token(\"https://cognitiveservices.azure.com/.default\").token\n",
    "print(f\"‚úÖ Ready! Token: {get_cu_token()[:20]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "12e670dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model defaults configured!\n"
     ]
    }
   ],
   "source": [
    "defaults = {\"modelDeployments\": {\"gpt-4.1\": GPT41_DEPLOYMENT, \"gpt-4.1-mini\": GPT41_MINI_DEPLOYMENT, \"text-embedding-3-large\": EMBEDDING_DEPLOYMENT}}\n",
    "resp = requests.patch(f\"{CU_ENDPOINT}/contentunderstanding/defaults?api-version={CU_API_VERSION}\",\n",
    "    headers={\"Authorization\": f\"Bearer {get_cu_token()}\", \"Content-Type\": \"application/json\"}, json=defaults)\n",
    "print(\"‚úÖ Model defaults configured!\" if resp.ok else f\"‚ùå Failed: {resp.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e2e05d",
   "metadata": {},
   "source": [
    "---\n",
    "# Part A: Document Analysis\n",
    "Use `prebuilt-layout` to extract text/tables from PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "84710c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CU client ready\n"
     ]
    }
   ],
   "source": [
    "class CUClient:\n",
    "    \"\"\"Simple Content Understanding client with AAD auth.\"\"\"\n",
    "    def __init__(self, endpoint, credential, api_version=\"2025-11-01\"):\n",
    "        self.endpoint, self.credential, self.api_version = endpoint.rstrip('/'), credential, api_version\n",
    "    \n",
    "    def _headers(self):\n",
    "        return {\"Authorization\": f\"Bearer {self.credential.get_token('https://cognitiveservices.azure.com/.default').token}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    def analyze(self, analyzer, inputs, poll_interval=2, max_wait=600):\n",
    "        url = f\"{self.endpoint}/contentunderstanding/analyzers/{analyzer}:analyze?api-version={self.api_version}\"\n",
    "        resp = requests.post(url, headers=self._headers(), json={\"inputs\": inputs})\n",
    "        if not resp.ok: return {\"error\": resp.text}\n",
    "        op_url = resp.headers.get('Operation-Location')\n",
    "        start = time.time()\n",
    "        while time.time() - start < max_wait:\n",
    "            r = requests.get(op_url, headers=self._headers()).json()\n",
    "            if r.get('status') == 'Succeeded': return r\n",
    "            if r.get('status') in ['Failed', 'Cancelled']: return {\"error\": r}\n",
    "            time.sleep(poll_interval)\n",
    "        return {\"error\": \"Timeout\"}\n",
    "\n",
    "cu = CUClient(CU_ENDPOINT, credential, CU_API_VERSION)\n",
    "print(\"‚úÖ CU client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d88c8e9",
   "metadata": {},
   "source": [
    "## Step 5: Analyze a Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample NASA technical document (publicly accessible)\n",
    "SAMPLE_PDF_URL = \"https://ntrs.nasa.gov/api/citations/19720018364/downloads/19720018364.pdf\"\n",
    "SAMPLE_TITLE = \"Apollo 14 Mission Report\"\n",
    "\n",
    "print(f\"üìÑ Sample Document: {SAMPLE_TITLE}\")\n",
    "print(f\"   URL: {SAMPLE_PDF_URL[:60]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de6248f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Analyzing: Apollo 14 Mission Report...\n",
      "‚úÖ Extracted 132,629 characters from 1 content block(s)\n"
     ]
    }
   ],
   "source": [
    "# Analyze document with prebuilt-layout (extracts text, tables, structure)\n",
    "print(f\"üìÑ Analyzing: {SAMPLE_TITLE}...\")\n",
    "doc_result = cu.analyze(\"prebuilt-layout\", [{\"url\": SAMPLE_PDF_URL}])\n",
    "\n",
    "if 'error' in doc_result:\n",
    "    print(f\"‚ùå Error: {doc_result['error']}\")\n",
    "else:\n",
    "    contents = doc_result.get('result', {}).get('contents', [])\n",
    "    markdown = contents[0].get('markdown', '') if contents else ''\n",
    "    print(f\"‚úÖ Extracted {len(markdown):,} characters from {len(contents)} content block(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae2e3357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üìù Extracted Content Preview\n",
       "\n",
       "2 (mix)\n",
       "\n",
       "NASA CR-120916\n",
       "\n",
       "(NASA-CR-120916) - DESIGN OF A TF34 TURBOFAN\n",
       "MIXER FOR REDUCTION OF FLAP IMPINGEMENT\n",
       "NOISE Final Report A. Chamay, et al\n",
       "(General Electric Co.) 2 Feb. 1972 131 p\n",
       "\n",
       "N72-26014\n",
       "\n",
       "Unclas\n",
       "CSCL 21E G3/02 32002\n",
       "\n",
       "\n",
       "![NASA](figures/1.1)\n",
       "\n",
       "\n",
       "DESIGN OF A TF34 TURBOFAN MIXER FOR\n",
       "REDUCTION OF FLAP IMPINGEMENT NOISE\n",
       "\n",
       "FINAL REPORT\n",
       "\n",
       "by A. Chamay, D.P. Edkins, R.B. Mishler and W.S. Clapper\n",
       "Reproduced by\n",
       "NATIONAL TECHNICAL\n",
       "INFORMATION SERVICE\n",
       "U S Department of Commerce\n",
       "Springfield VA 22151\n",
       "\n",
       "GENERAL ELECTRIC COMPANY\n",
       "AIRCRAFT ENGINE GROUP\n",
       "LYNN, MASSACHUSETTS/CINCINNATI OHIO\n",
       "\n",
       "Prepared for\n",
       "NATIONAL AERONAUTICS AND SPACE ADMINISTRATION\n",
       "February 2, 1972\n",
       "\n",
       "NASA Lewis Research Center\n",
       "Cleveland, Ohio\n",
       "N.E. Samanich\n",
       "Project Manager\n",
       "\n",
       "CONTRACT NAS 3-14338 Modification 2\n",
       "\n",
       "RECEIVED\n",
       "JUN 1972\n",
       "GISA STI FACILITY\n",
       "INZUT BRAMEN\n",
       "67 8 9 101112 13 14 1J\n",
       "\n",
       "/3/2\n",
       "\n",
       "<!-- PageBreak -->\n",
       "\n",
       "<!-- PageHeader: NASA CR-120916 -->\n",
       "\n",
       "\n",
       "# FINAL REPORT\n",
       "\n",
       "DESIGN OF A TF34 TURBOFAN MIXER FOR REDUCTION\n",
       "OF FLAP IMPINGEMENT NOISE\n",
       "\n",
       "by\n",
       "\n",
       "A. Chamay, D. P. Edkins, R. B. Mishler and W. S. Clapper\n",
       "\n",
       "General Electric Company\n",
       "Aircraft Engine Group\n",
       "Lynn, Massachusetts/Cincinnati, Ohio\n",
       "\n",
       "prepared for\n",
       "NATIONAL AERONAUTICS AND SPACE ADMINISTRATION\n",
       "February 2, 1972\n",
       "\n",
       "CONTRACT NAS3-14338 Modification 2\n",
       "\n",
       "NASA Lewis Research Center\n",
       "Cleveland, Ohio\n",
       "N. E. Samanich - Project Manager\n",
       "\n",
       "<!-- PageBreak -->\n",
       "\n",
       "<!-- PageHeader: PRECEDING PAGE BLANK NOT FILMED -->\n",
       "\n",
       "\n",
       "## TABLE OF CONTENTS\n",
       "\n",
       "\n",
       "<table>\n",
       "<tr>\n",
       "<th></th>\n",
       "<th></th>\n",
       "<th>Page</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>ABSTRACT</td>\n",
       "<td></td>\n",
       "<td>iv</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>SUMMARY</td>\n",
       "<td></td>\n",
       "<td></td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>INTRODUCTION</td>\n",
       "<td></td>\n",
       "<td>5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>TECHNICAL DISCUSSION</td>\n",
       "<td></td>\n",
       "<td>7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Program Objectives</td>\n",
       "<td></td>\n",
       "<td>7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Program Description and Schedule</td>\n",
       "<td></td>\n",
       "<td>7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Task I Study</td>\n",
       "<td></td>\n",
       "<td>7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Review of Design Data</td>\n",
       "<td></td>\n",
       "<td>11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>Engine Cycle Data</td>\n",
       "<td></td>\n",
       "<td>16<\n",
       "\n",
       "*... (truncated)*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display extracted content preview\n",
    "if 'error' not in doc_result and markdown:\n",
    "    display(Markdown(f\"### üìù Extracted Content Preview\\n\\n{markdown[:2000]}\" + (\"\\n\\n*... (truncated)*\" if len(markdown) > 2000 else \"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddfe2e2",
   "metadata": {},
   "source": [
    "---\n",
    "# Part B: Video Analysis\n",
    "Use `prebuilt-videoSearch` to extract keyframes, transcripts, and segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "39fddb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Analyzing NASA Crawler-Transporter footage (may take a few minutes)...\n",
      "‚úÖ Found 4 segments, 626 keyframes, 1 transcript phrases\n"
     ]
    }
   ],
   "source": [
    "## Step 6: Analyze NASA Video\n",
    "NASA_VIDEO_URL = \"https://images-assets.nasa.gov/video/KSC-19640101-MH-NAS01-0001-The_Crawler_Transporter_The_Beginning_Historical_Footage-B_2309/KSC-19640101-MH-NAS01-0001-The_Crawler_Transporter_The_Beginning_Historical_Footage-B_2309~orig.mp4\"\n",
    "\n",
    "print(\"üé¨ Analyzing NASA Crawler-Transporter footage (may take a few minutes)...\")\n",
    "video_result = cu.analyze(\"prebuilt-videoSearch\", [{\"url\": NASA_VIDEO_URL}], poll_interval=5, max_wait=600)\n",
    "\n",
    "if 'error' in video_result:\n",
    "    print(f\"‚ùå Error: {video_result['error']}\")\n",
    "else:\n",
    "    contents = video_result.get('result', {}).get('contents', [])\n",
    "    keyframes = sum(len(c.get('KeyFrameTimesMs', [])) for c in contents)\n",
    "    phrases = sum(len(c.get('transcriptPhrases', [])) for c in contents)\n",
    "    print(f\"‚úÖ Found {len(contents)} segments, {keyframes} keyframes, {phrases} transcript phrases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a21395b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üé¨ Segment 1 (0s - 26s):\n",
      "   The video segment begins with a color test pattern screen labeled 'KSC-TV' and no visible action or people. This static test pattern continues for the first 26 seconds, indicating a broadcast or recor...\n",
      "\n",
      "üé¨ Segment 2 (28s - 109s):\n",
      "   The video shows detailed footage of a large tracked vehicle, likely a heavy construction or military machine, focusing on its massive tracks and mechanical components. The camera captures close-up vie...\n",
      "\n",
      "üé¨ Segment 3 (111s - 330s):\n",
      "   The video shifts to the interior control cabin of the tracked vehicle, showing the operator's console with various gauges, levers, and controls. The camera pans around the cabin, highlighting the cont...\n",
      "\n",
      "üé¨ Segment 4 (330s - 627s):\n",
      "   The video continues with detailed close-up shots of the tracked vehicle's large metal treads moving over gravel, showing the individual tread plates and their articulation. The camera captures various...\n"
     ]
    }
   ],
   "source": [
    "# Display video segment summaries\n",
    "if 'error' not in video_result:\n",
    "    for i, seg in enumerate(contents):\n",
    "        start_s, end_s = seg.get('startTimeMs', 0)//1000, seg.get('endTimeMs', 0)//1000\n",
    "        summary = seg.get('fields', {}).get('Summary', {}).get('valueString', 'N/A')\n",
    "        print(f\"\\nüé¨ Segment {i+1} ({start_s}s - {end_s}s):\")\n",
    "        print(f\"   {summary[:200]}{'...' if len(summary) > 200 else ''}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c80bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "**Content Understanding** extracts structured data from multimodal content:\n",
    "\n",
    "| Analyzer | Input | Output |\n",
    "|----------|-------|--------|\n",
    "| `prebuilt-layout` | Documents (PDF, images) | Markdown text, tables, structure |\n",
    "| `prebuilt-videoSearch` | Video files | Segments, keyframes, transcripts, summaries |\n",
    "| `prebuilt-audioSearch` | Audio files | Transcription, speaker diarization |\n",
    "| `prebuilt-imageSearch` | Images | Descriptions, object detection |\n",
    "\n",
    "**Key concepts:**\n",
    "- Requires GPT-4.1, GPT-4.1-mini, and text-embedding-3-large in the same resource\n",
    "- Uses async polling pattern (submit ‚Üí poll Operation-Location ‚Üí get result)\n",
    "- Supports both URL and base64-encoded content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5b1aa01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup (uncomment to delete resources)\n",
    "# !az group delete -n \"{RG}\" --yes --no-wait"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
