{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd362c9a",
   "metadata": {},
   "source": [
    "# Lab 8: Deep Research with NASA Technical Reports\n",
    "\n",
    "Use **o3-deep-research** with **function calling** to research NASA NTRS documents!\n",
    "\n",
    "> ‚úÖ **Azure OpenAI Compatible**\n",
    "> \n",
    "> This notebook uses the **Chat Completions API with function calling** instead of MCP.\n",
    "> This approach works with Azure today.\n",
    "\n",
    "## What is o3-deep-research?\n",
    "\n",
    "The `o3-deep-research` model is designed for **advanced research tasks**. It can:\n",
    "- Browse, analyze, and synthesize information from **hundreds of sources**\n",
    "- Produce **comprehensive, citation-rich reports**\n",
    "- Use **multi-step reasoning** with tools\n",
    "- Run **code for complex analysis**\n",
    "\n",
    "| Standard Chat | o3-deep-research |\n",
    "|--------------|------------------|\n",
    "| Single model call | Multi-step reasoning with tool use |\n",
    "| No tool loops | **Agentic loop** with search/fetch |\n",
    "| Instant response | Extended reasoning for complex queries |\n",
    "| Generic answers | **Cited, sourced** research reports |\n",
    "\n",
    "## Data Source: NASA NTRS\n",
    "\n",
    "We download **NASA's Technical Reports Server (NTRS)** public metadata:\n",
    "- 800,000+ NASA technical documents\n",
    "- Original mission reports, scientific papers, technical memoranda\n",
    "- Filter for specific topics (default: **Apollo 14**)\n",
    "- Index into **Foundry IQ** knowledge base\n",
    "\n",
    "## Prerequisites\n",
    "- Completed **Lab 1a** (Landing Zone) - for embeddings and APIM gateway\n",
    "- `.env` file with APIM_URL, APIM_KEY, AI_ENDPOINT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a0c6e",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdabe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas requests azure-identity azure-search-documents pypdf matplotlib ijson openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee45c1",
   "metadata": {},
   "source": [
    "## Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, Dict, List, Any\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Modify these for your use case\n",
    "# =============================================================================\n",
    "\n",
    "SEARCH_TERM = \"Apollo 14\"      # What to research\n",
    "MAX_PDF_SIZE_MB = 100          # Maximum total PDF download size\n",
    "DEEP_RESEARCH_MODEL = \"o3-deep-research\"\n",
    "MAX_RESEARCH_ITERATIONS = 10   # Maximum tool call iterations\n",
    "\n",
    "# Resource names\n",
    "RG = \"deep-research-lab\"\n",
    "LOCATION = \"eastus2\"\n",
    "HUB_RG = \"foundry-lz-parent\"   # Landing Zone resource group from Lab 1a\n",
    "\n",
    "# =============================================================================\n",
    "# Load environment from Lab 1a\n",
    "# =============================================================================\n",
    "\n",
    "env_path = Path(\"../.env\")\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        if '=' in line and not line.startswith('#'):\n",
    "            key, value = line.split('=', 1)\n",
    "            os.environ[key.strip()] = value.strip()\n",
    "\n",
    "APIM_URL = os.environ.get(\"APIM_URL\", \"\")\n",
    "APIM_KEY = os.environ.get(\"APIM_KEY\", \"\")\n",
    "AI_ENDPOINT = os.environ.get(\"AI_ENDPOINT\", \"\")\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"gpt-4.1-mini\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "\n",
    "# Extract hub account name and APIM name from endpoints\n",
    "import re\n",
    "HUB_ACCOUNT_NAME = \"\"\n",
    "APIM_NAME = \"\"\n",
    "if AI_ENDPOINT:\n",
    "    match = re.match(r'https://([^.]+)\\.', AI_ENDPOINT)\n",
    "    if match:\n",
    "        HUB_ACCOUNT_NAME = match.group(1)\n",
    "if APIM_URL:\n",
    "    match = re.match(r'https://([^.]+)\\.', APIM_URL)\n",
    "    if match:\n",
    "        APIM_NAME = match.group(1)\n",
    "\n",
    "# Get current user\n",
    "PRINCIPAL_ID = subprocess.run(\n",
    "    'az ad signed-in-user show --query id -o tsv',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "\n",
    "# Verify configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not APIM_URL or not APIM_KEY:\n",
    "    print(\"‚ö†Ô∏è  [WARN] Missing APIM_URL or APIM_KEY in .env file!\")\n",
    "    print(\"         Please complete Lab 1a first\")\n",
    "else:\n",
    "    print(\"‚úÖ [OK] Azure Configuration Loaded\")\n",
    "    print(f\"       APIM Gateway:  {APIM_URL[:50]}...\")\n",
    "    print(f\"       APIM Name:     {APIM_NAME}\")\n",
    "    print(f\"       Hub Account:   {HUB_ACCOUNT_NAME}\")\n",
    "\n",
    "print()\n",
    "print(f\"üìö Research Term: {SEARCH_TERM}\")\n",
    "print(f\"ü§ñ Model: {DEEP_RESEARCH_MODEL}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee3c3a",
   "metadata": {},
   "source": [
    "## Step 3: Deploy Infrastructure\n",
    "\n",
    "This creates:\n",
    "- **Norway East Hub**: o3-deep-research deployment (region-specific)\n",
    "- **APIM Backend**: Routes chat completions to Norway East\n",
    "- **Azure AI Search**: For Foundry IQ knowledge bases\n",
    "\n",
    "‚è±Ô∏è Takes ~5-7 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e800e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\n",
      "----------  -----------------\n",
      "eastus2     deep-research-lab\n"
     ]
    }
   ],
   "source": [
    "!az group create -n \"{RG}\" -l \"{LOCATION}\" -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d28ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy spoke resources with Norway East hub for o3-deep-research\n",
    "!az deployment group create -g \"{RG}\" --template-file spoke.bicep \\\n",
    "    -p deployerPrincipalId=\"{PRINCIPAL_ID}\" \\\n",
    "    -p hubResourceGroup=\"{HUB_RG}\" \\\n",
    "    -p hubAccountName=\"{HUB_ACCOUNT_NAME}\" \\\n",
    "    -p apimName=\"{APIM_NAME}\" \\\n",
    "    -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499153a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get deployment outputs\n",
    "outputs = json.loads(subprocess.run(\n",
    "    f'az deployment group show -g \"{RG}\" -n spoke --query properties.outputs -o json',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout)\n",
    "\n",
    "SEARCH_ENDPOINT = outputs['searchEndpoint']['value']\n",
    "SEARCH_NAME = outputs['searchName']['value']\n",
    "NORWAYEAST_HUB_ENDPOINT = outputs['norwayeastHubEndpoint']['value']\n",
    "NORWAYEAST_HUB_NAME = outputs['norwayeastHubName']['value']\n",
    "\n",
    "print(f\"‚úÖ Deployment Complete!\")\n",
    "print(f\"   Search Service:     {SEARCH_NAME}\")\n",
    "print(f\"   Search Endpoint:    {SEARCH_ENDPOINT}\")\n",
    "print(f\"   Norway East Hub:    {NORWAYEAST_HUB_NAME}\")\n",
    "print(f\"   Norway East Endpoint: {NORWAYEAST_HUB_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8f80b131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RBAC permissions ready!\n"
     ]
    }
   ],
   "source": [
    "# Wait for RBAC propagation\n",
    "for i in range(60, 0, -10):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"‚è≥ Waiting for RBAC to propagate... {i}s\")\n",
    "    time.sleep(10)\n",
    "clear_output(wait=True)\n",
    "print(\"‚úÖ RBAC permissions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13903436",
   "metadata": {},
   "source": [
    "## Step 4: Download NASA NTRS Metadata\n",
    "\n",
    "Download the full NASA Technical Reports Server metadata (~2GB compressed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f94001bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadata already exists: ntrs_data/ntrs-public-metadata.json.gz (398.9 MB)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "NTRS_METADATA_URL = \"https://www.sti.nasa.gov/docs/ntrs-public-metadata.json.gz\"\n",
    "DATA_DIR = Path(\"./ntrs_data\")\n",
    "METADATA_FILE = DATA_DIR / \"ntrs-public-metadata.json.gz\"\n",
    "PDF_DIR = DATA_DIR / \"pdfs\"\n",
    "\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "PDF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Download metadata if not present\n",
    "if not METADATA_FILE.exists():\n",
    "    print(f\"üì• Downloading NTRS metadata (~2GB compressed)...\")\n",
    "    !curl -L -o \"{METADATA_FILE}\" \"{NTRS_METADATA_URL}\" --progress-bar\n",
    "    print(f\"‚úÖ Downloaded to {METADATA_FILE}\")\n",
    "else:\n",
    "    size_mb = METADATA_FILE.stat().st_size / (1024 * 1024)\n",
    "    print(f\"‚úÖ Metadata already exists: {METADATA_FILE} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300beae4",
   "metadata": {},
   "source": [
    "## Step 5: Filter Documents by Search Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "61359404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Streaming metadata for 'Apollo 14'...\n",
      "   Scanned 550,000 docs, found 451 matches...\n",
      "‚úÖ Found 461 documents matching 'Apollo 14'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19740072936</td>\n",
       "      <td>Apollo 14 (mission H-3) Baseline Mission Profile</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19710001731</td>\n",
       "      <td>Apollo operations handbook, extravehicular mob...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19710004668</td>\n",
       "      <td>Apollo/Saturn 5 consolidated instrumentation p...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19710005842</td>\n",
       "      <td>Apollo 14 /AS-509/ operational trajectory for ...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19710010322</td>\n",
       "      <td>Apollo 14 laser ranging retro-reflector experi...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19950023897</td>\n",
       "      <td>Apollo 14: Shepard Hitting Golf Ball on Moon</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19710021481</td>\n",
       "      <td>Preliminary geologic investigations of the Apo...</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19710021482</td>\n",
       "      <td>Soil mechanics experiment</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19710021486</td>\n",
       "      <td>Suprathermal ion detector experiment /lunar io...</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19710027929</td>\n",
       "      <td>Apollo 14 mission, 5 day report</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  year\n",
       "0  19740072936   Apollo 14 (mission H-3) Baseline Mission Profile  1969\n",
       "1  19710001731  Apollo operations handbook, extravehicular mob...  1970\n",
       "2  19710004668  Apollo/Saturn 5 consolidated instrumentation p...  1970\n",
       "3  19710005842  Apollo 14 /AS-509/ operational trajectory for ...  1970\n",
       "4  19710010322  Apollo 14 laser ranging retro-reflector experi...  1970\n",
       "5  19950023897       Apollo 14: Shepard Hitting Golf Ball on Moon  1970\n",
       "6  19710021481  Preliminary geologic investigations of the Apo...  1971\n",
       "7  19710021482                          Soil mechanics experiment  1971\n",
       "8  19710021486  Suprathermal ion detector experiment /lunar io...  1971\n",
       "9  19710027929                    Apollo 14 mission, 5 day report  1971"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ijson\n",
    "\n",
    "print(f\"üîç Streaming metadata for '{SEARCH_TERM}'...\")\n",
    "\n",
    "search_lower = SEARCH_TERM.lower()\n",
    "filtered_docs = []\n",
    "doc_count = 0\n",
    "\n",
    "with gzip.open(METADATA_FILE, 'rb') as f:\n",
    "    for doc_id, doc in ijson.kvitems(f, ''):\n",
    "        doc_count += 1\n",
    "        if doc_count % 50000 == 0:\n",
    "            print(f\"   Scanned {doc_count:,} docs, found {len(filtered_docs)} matches...\", end='\\r')\n",
    "        \n",
    "        title = doc.get('title', '') or ''\n",
    "        abstract = doc.get('abstract', '') or ''\n",
    "        \n",
    "        if search_lower in title.lower() or search_lower in abstract.lower():\n",
    "            doc['ntrs_id'] = doc_id\n",
    "            filtered_docs.append(doc)\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(filtered_docs)} documents matching '{SEARCH_TERM}'\")\n",
    "\n",
    "if filtered_docs:\n",
    "    df = pd.DataFrame([{\n",
    "        \"id\": d.get('ntrs_id'),\n",
    "        \"title\": d.get('title', 'N/A')[:60],\n",
    "        \"year\": d.get('publications', [{}])[0].get('publicationDate', '')[:4] if d.get('publications') else 'N/A',\n",
    "    } for d in filtered_docs[:10]])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8637294",
   "metadata": {},
   "source": [
    "## Step 6: Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9641fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading PDFs (max 100 MB total)...\n",
      "  19740072936: Apollo 14 (mission H-3) Baseline Mission... ‚úÖ (810.9 KB) [0.8/100 MB]\n",
      "  19710001731: Apollo operations handbook, extravehicul... ‚úÖ (7576.6 KB) [8.2/100 MB]\n",
      "  19710004668: Apollo/Saturn 5 consolidated instrumenta... ‚úÖ (3098.6 KB) [11.2/100 MB]\n",
      "  19710005842: Apollo 14 /AS-509/ operational trajector... ‚úÖ (22696.0 KB) [33.4/100 MB]\n",
      "  19710010322: Apollo 14 laser ranging retro-reflector ... ‚úÖ (19579.8 KB) [52.5/100 MB]\n",
      "  19950023897: Apollo 14: Shepard Hitting Golf Ball on ... (no PDF)\n",
      "  19710021481: Preliminary geologic investigations of t... (no PDF)\n",
      "  19710021482: Soil mechanics experiment... (no PDF)\n",
      "  19710021486: Suprathermal ion detector experiment /lu... (no PDF)\n",
      "  19710027929: Apollo 14 mission, 5 day report... ‚úÖ (1119.4 KB) [53.6/100 MB]\n",
      "  19710055248: Ar 40/Ar 39 ages from Fra Mauro... (no PDF)\n",
      "  19710058684: Chemical composition of Apollo 14 soils ... (no PDF)\n",
      "  19710061141: Ages of crystalline rocks from Fra Mauro... (no PDF)\n",
      "  19710061288: Medical results of Apollo 14 - Implicati... (no PDF)\n",
      "  19720007220: Apollo 14 composite casting demonstratio... ‚úÖ (46911.3 KB) [99.4/100 MB]\n",
      "  19720010767: Apollo 14 lunar photography.  Part 1:  D... ‚úÖ (1406.5 KB) [100.8/100 MB]\n",
      "\n",
      "‚úÖ Downloaded 8 PDFs (100.8 MB)\n"
     ]
    }
   ],
   "source": [
    "NTRS_BASE = \"https://ntrs.nasa.gov\"\n",
    "NTRS_API_BASE = f\"{NTRS_BASE}/api\"\n",
    "\n",
    "def get_downloads(ntrs_id: str) -> list:\n",
    "    \"\"\"Get available PDF downloads for a document.\"\"\"\n",
    "    try:\n",
    "        resp = requests.get(f\"{NTRS_API_BASE}/citations/{ntrs_id}\", timeout=30)\n",
    "        if resp.ok:\n",
    "            return [d for d in resp.json().get('downloads', []) \n",
    "                    if d.get('mimetype', '').lower() == 'application/pdf']\n",
    "    except: \n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def download_pdf(ntrs_id: str, dl: dict) -> tuple:\n",
    "    \"\"\"Download a PDF and return (filepath, size).\"\"\"\n",
    "    try:\n",
    "        rel_path = dl.get('links', {}).get('pdf')\n",
    "        if rel_path:\n",
    "            pdf_url = f\"{NTRS_BASE}{rel_path}\"\n",
    "        else:\n",
    "            pdf_url = f\"{NTRS_API_BASE}/citations/{ntrs_id}/downloads/{dl.get('name', ntrs_id + '.pdf')}\"\n",
    "        \n",
    "        filepath = PDF_DIR / f\"{ntrs_id}_{dl.get('name', 'doc.pdf').replace('.pdf', '')}.pdf\"\n",
    "        if filepath.exists():\n",
    "            return filepath, filepath.stat().st_size\n",
    "        \n",
    "        resp = requests.get(pdf_url, timeout=120, stream=True)\n",
    "        if resp.ok and 'application/pdf' in resp.headers.get('content-type', ''):\n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in resp.iter_content(8192):\n",
    "                    f.write(chunk)\n",
    "            return filepath, filepath.stat().st_size\n",
    "    except:\n",
    "        pass\n",
    "    return None, 0\n",
    "\n",
    "print(f\"üì• Downloading PDFs (max {MAX_PDF_SIZE_MB} MB total)...\")\n",
    "downloaded = []\n",
    "total_bytes = 0\n",
    "\n",
    "for doc in filtered_docs:\n",
    "    if total_bytes >= MAX_PDF_SIZE_MB * 1024 * 1024:\n",
    "        break\n",
    "    \n",
    "    ntrs_id = doc['ntrs_id']\n",
    "    title = doc.get('title', 'N/A')[:40]\n",
    "    print(f\"  {ntrs_id}: {title}...\", end=\" \")\n",
    "    \n",
    "    downloads = get_downloads(ntrs_id)\n",
    "    if not downloads:\n",
    "        print(\"(no PDF)\")\n",
    "        continue\n",
    "    \n",
    "    filepath, sz = download_pdf(ntrs_id, downloads[0])\n",
    "    if filepath:\n",
    "        total_bytes += sz\n",
    "        downloaded.append({\n",
    "            'ntrs_id': ntrs_id,\n",
    "            'title': doc.get('title', ''),\n",
    "            'abstract': doc.get('abstract', ''),\n",
    "            'authors': [a.get('name', '') for a in doc.get('authorAffiliations', [])],\n",
    "            'year': doc.get('publications', [{}])[0].get('publicationDate', '')[:4] if doc.get('publications') else '',\n",
    "            'filepath': filepath\n",
    "        })\n",
    "        print(f\"‚úÖ ({sz/1024:.1f} KB) [{total_bytes/1024/1024:.1f}/{MAX_PDF_SIZE_MB} MB]\")\n",
    "    else:\n",
    "        print(\"(error)\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(f\"\\n‚úÖ Downloaded {len(downloaded)} PDFs ({total_bytes/1024/1024:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf2fe8",
   "metadata": {},
   "source": [
    "## Step 7: Extract Text from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19802fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Extracting text from PDFs...\n",
      "  19740072936_19740072936.pdf... ‚úÖ (22,884 chars)\n",
      "  19710001731_19710001731.pdf... ‚úÖ (39,142 chars)\n",
      "  19710004668_19710004668.pdf... ‚úÖ (37,973 chars)\n",
      "  19710005842_19710005842.pdf... ‚úÖ (53,520 chars)\n",
      "  19710010322_19710010322.pdf... ‚úÖ (35,832 chars)\n",
      "  19710027929_19710027929.pdf... ‚úÖ (38,249 chars)\n",
      "  19720007220_19720007220.pdf... ‚úÖ (72,354 chars)\n",
      "  19720010767_19720010767.pdf... ‚úÖ (35,262 chars)\n",
      "\n",
      "‚úÖ Extracted text from 8 documents\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def extract_text(filepath: Path, max_pages: int = 50) -> str:\n",
    "    \"\"\"Extract text from PDF.\"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(filepath)\n",
    "        return \"\\n\\n\".join([p.extract_text() or \"\" for p in reader.pages[:max_pages]])\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"üìÑ Extracting text from PDFs...\")\n",
    "documents = []\n",
    "\n",
    "for doc in downloaded:\n",
    "    print(f\"  {doc['filepath'].name}...\", end=\" \")\n",
    "    text = extract_text(doc['filepath'])\n",
    "    if text and len(text) > 100:\n",
    "        full_text = f\"\"\"Title: {doc['title']}\n",
    "Authors: {', '.join(doc['authors'])}\n",
    "Year: {doc['year']}\n",
    "\n",
    "Abstract:\n",
    "{doc['abstract']}\n",
    "\n",
    "Full Text:\n",
    "{text}\"\"\"\n",
    "        documents.append({\n",
    "            'ntrs_id': doc['ntrs_id'], \n",
    "            'title': doc['title'], \n",
    "            'text': full_text, \n",
    "            'year': doc['year'], \n",
    "        })\n",
    "        print(f\"‚úÖ ({len(text):,} chars)\")\n",
    "    else:\n",
    "        print(\"-\")\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted text from {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d4659",
   "metadata": {},
   "source": [
    "## Step 8: Create Azure AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "10b1c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index 'apollo-14-research' created!\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SearchField, SearchFieldDataType,\n",
    "    SemanticConfiguration, SemanticField, SemanticPrioritizedFields, SemanticSearch,\n",
    "    VectorSearch, HnswAlgorithmConfiguration, VectorSearchProfile\n",
    ")\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "index_client = SearchIndexClient(endpoint=SEARCH_ENDPOINT, credential=credential)\n",
    "\n",
    "INDEX_NAME = f\"{SEARCH_TERM.lower().replace(' ', '-')}-research\"\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True),\n",
    "        SearchField(name=\"parent_id\", type=\"Edm.String\", filterable=True),\n",
    "        SearchField(name=\"chunk_index\", type=\"Edm.Int32\", sortable=True),\n",
    "        SearchField(name=\"ntrs_id\", type=\"Edm.String\", filterable=True),\n",
    "        SearchField(name=\"title\", type=\"Edm.String\", searchable=True),\n",
    "        SearchField(name=\"year\", type=\"Edm.String\", filterable=True, facetable=True),\n",
    "        SearchField(name=\"subjects\", type=\"Collection(Edm.String)\", filterable=True, facetable=True),\n",
    "        SearchField(name=\"content\", type=\"Edm.String\", searchable=True),\n",
    "        SearchField(name=\"content_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    vector_search_dimensions=3072, vector_search_profile_name=\"vector-profile\", searchable=True),\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"hnsw-algo\")],\n",
    "        profiles=[VectorSearchProfile(name=\"vector-profile\", algorithm_configuration_name=\"hnsw-algo\")]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic-config\",\n",
    "        configurations=[SemanticConfiguration(name=\"semantic-config\", prioritized_fields=SemanticPrioritizedFields(\n",
    "            content_fields=[SemanticField(field_name=\"content\")], title_field=SemanticField(field_name=\"title\")\n",
    "        ))]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Retry loop for RBAC propagation\n",
    "for attempt in range(6):\n",
    "    try:\n",
    "        index_client.create_or_update_index(index)\n",
    "        print(f\"‚úÖ Index '{INDEX_NAME}' created!\")\n",
    "        break\n",
    "    except HttpResponseError as e:\n",
    "        if 'Forbidden' in str(e) and attempt < 5:\n",
    "            print(f\"   RBAC not ready, waiting 30s... (attempt {attempt+1}/6)\")\n",
    "            time.sleep(30)\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e549fb",
   "metadata": {},
   "source": [
    "## Step 9: Generate Embeddings & Upload to Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76ac9b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model working! Dimension: 3072\n",
      "\n",
      "üìÑ Chunking 8 documents...\n",
      "  [1/8] Apollo 14 (mission H-3) Baseline Mi... ‚Üí 7 chunks\n",
      "\n",
      "  [2/8] Apollo operations handbook, extrave... ‚Üí 14 chunks\n",
      "\n",
      "  [3/8] Apollo/Saturn 5 consolidated instru... ‚Üí 14 chunks\n",
      "\n",
      "  [4/8] Apollo 14 /AS-509/ operational traj... ‚Üí 19 chunks\n",
      "\n",
      "  [5/8] Apollo 14 laser ranging retro-refle... ‚Üí 13 chunks\n",
      "\n",
      "  [6/8] Apollo 14 mission, 5 day report... ‚Üí 14 chunks\n",
      "\n",
      "  [7/8] Apollo 14 composite casting demonst... ‚Üí 30 chunks\n",
      "\n",
      "  [8/8] Apollo 14 lunar photography.  Part ... ‚Üí 14 chunks\n",
      "\n",
      "\n",
      "‚úÖ Created 125 chunks from 8 documents\n",
      "\n",
      "üì§ Uploading to Azure AI Search...\n",
      "‚úÖ Uploaded 125 chunks to index 'apollo-14-research'!\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 4000\n",
    "CHUNK_OVERLAP = 400\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> list[str]:\n",
    "    \"\"\"Split text into chunks at semantic boundaries.\"\"\"\n",
    "    if len(text) <= chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        \n",
    "        if end >= len(text):\n",
    "            chunks.append(text[start:])\n",
    "            break\n",
    "        \n",
    "        chunk = text[start:end]\n",
    "        split_pos = chunk.rfind('\\n\\n')\n",
    "        if split_pos > chunk_size * 0.5:\n",
    "            end = start + split_pos + 2\n",
    "        else:\n",
    "            for pattern in ['. ', '.\\n', '? ', '! ']:\n",
    "                pos = chunk.rfind(pattern)\n",
    "                if pos > chunk_size * 0.5:\n",
    "                    split_pos = pos\n",
    "                    break\n",
    "            if split_pos > chunk_size * 0.5:\n",
    "                end = start + split_pos + 2\n",
    "            else:\n",
    "                split_pos = chunk.rfind(' ')\n",
    "                if split_pos > 0:\n",
    "                    end = start + split_pos + 1\n",
    "        \n",
    "        chunks.append(text[start:end].strip())\n",
    "        start = end - overlap\n",
    "    \n",
    "    return [c for c in chunks if c.strip()]\n",
    "\n",
    "def get_embedding(text: str, max_chars: int = 8191, max_retries: int = 5) -> list:\n",
    "    \"\"\"Get embedding with exponential backoff.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        resp = requests.post(\n",
    "            f\"{APIM_URL}/deployments/{EMBEDDING_MODEL}/embeddings?api-version=2024-10-21\",\n",
    "            headers={\"api-key\": APIM_KEY, \"Content-Type\": \"application/json\"},\n",
    "            json={\"input\": text[:max_chars], \"model\": EMBEDDING_MODEL}\n",
    "        )\n",
    "        if resp.status_code == 429:\n",
    "            wait = (2 ** attempt) + 1\n",
    "            print(f\"‚è≥ Rate limited, waiting {wait}s...\", end=\" \", flush=True)\n",
    "            time.sleep(wait)\n",
    "            continue\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()[\"data\"][0][\"embedding\"]\n",
    "    raise Exception(\"Max retries exceeded\")\n",
    "\n",
    "# Test embedding\n",
    "test_emb = get_embedding(\"Apollo 14 lunar mission\")\n",
    "print(f\"‚úÖ Embedding model working! Dimension: {len(test_emb)}\")\n",
    "\n",
    "# Generate chunks and embeddings\n",
    "print(f\"\\nüìÑ Chunking {len(documents)} documents...\")\n",
    "search_docs = []\n",
    "total_chunks = 0\n",
    "\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    chunks = chunk_text(doc['text'])\n",
    "    print(f\"  [{doc_idx+1}/{len(documents)}] {doc['title'][:35]}... ‚Üí {len(chunks)} chunks\")\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        embed_text = f\"{doc['title']}\\n\\n{chunk}\"\n",
    "        \n",
    "        search_docs.append({\n",
    "            \"id\": f\"{doc_idx+1}_{chunk_idx}\",\n",
    "            \"parent_id\": str(doc_idx + 1),\n",
    "            \"chunk_index\": chunk_idx,\n",
    "            \"ntrs_id\": doc['ntrs_id'],\n",
    "            \"title\": doc['title'],\n",
    "            \"year\": doc['year'],\n",
    "            \"content\": chunk,\n",
    "            \"content_vector\": get_embedding(embed_text)\n",
    "        })\n",
    "        total_chunks += 1\n",
    "        time.sleep(0.5)\n",
    "    print()\n",
    "\n",
    "print(f\"\\n‚úÖ Created {total_chunks} chunks from {len(documents)} documents\")\n",
    "\n",
    "# Upload\n",
    "print(f\"\\nüì§ Uploading to Azure AI Search...\")\n",
    "with SearchIndexingBufferedSender(endpoint=SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=credential) as sender:\n",
    "    sender.upload_documents(documents=search_docs)\n",
    "\n",
    "print(f\"‚úÖ Uploaded {len(search_docs)} chunks to index '{INDEX_NAME}'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb6c8a",
   "metadata": {},
   "source": [
    "## Step 10: Create Foundry IQ Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "74cfeefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Foundry IQ client initialized\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FOUNDRY IQ CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "class FoundryIQClient:\n",
    "    \"\"\"Client for Foundry IQ knowledge bases.\"\"\"\n",
    "    \n",
    "    def __init__(self, search_endpoint: str, get_token):\n",
    "        self.search_endpoint = search_endpoint.rstrip('/')\n",
    "        self.get_token = get_token\n",
    "        self.api_version = \"2025-11-01-preview\"\n",
    "    \n",
    "    def _headers(self):\n",
    "        return {\"Authorization\": f\"Bearer {self.get_token()}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    def _parse_response(self, resp):\n",
    "        \"\"\"Parse response, handling empty bodies for 2xx responses.\"\"\"\n",
    "        if resp.ok:\n",
    "            if resp.text:\n",
    "                return resp.json()\n",
    "            else:\n",
    "                return {\"status\": \"success\", \"code\": resp.status_code}\n",
    "        else:\n",
    "            return {\"error\": resp.status_code, \"message\": resp.text}\n",
    "    \n",
    "    def create_source(self, name: str, index_name: str, content_fields: list, title_field: str, url_field: str = None):\n",
    "        \"\"\"Create a knowledge source pointing to an existing search index.\"\"\"\n",
    "        # Build source_data_fields from content_fields and title_field\n",
    "        source_data_fields = [{\"name\": f} for f in content_fields]\n",
    "        if title_field:\n",
    "            source_data_fields.append({\"name\": title_field})\n",
    "        \n",
    "        body = {\n",
    "            \"name\": name,\n",
    "            \"kind\": \"searchIndex\",\n",
    "            \"description\": f\"Knowledge source for {index_name}\",\n",
    "            \"searchIndexParameters\": {\n",
    "                \"searchIndexName\": index_name,\n",
    "                \"semanticConfigurationName\": \"semantic-config\",\n",
    "                \"sourceDataFields\": source_data_fields,\n",
    "                \"searchFields\": []\n",
    "            }\n",
    "        }\n",
    "        resp = requests.put(f\"{self.search_endpoint}/knowledgesources/{name}?api-version={self.api_version}\",\n",
    "                           headers=self._headers(), json=body)\n",
    "        return self._parse_response(resp)\n",
    "    \n",
    "    def create_kb(self, name: str, sources: list, description: str, apim_url: str, apim_key: str, model: str):\n",
    "        \"\"\"Create a knowledge base that references one or more knowledge sources.\"\"\"\n",
    "        body = {\n",
    "            \"name\": name,\n",
    "            \"knowledgeSources\": [{\"name\": s} for s in sources],\n",
    "            \"description\": description,\n",
    "            \"models\": [\n",
    "                {\n",
    "                    \"kind\": \"azureOpenAI\",\n",
    "                    \"azureOpenAIParameters\": {\n",
    "                        \"resourceUri\": apim_url.replace('/openai', ''),\n",
    "                        \"deploymentId\": model,\n",
    "                        \"modelName\": model,\n",
    "                        \"apiKey\": apim_key\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"retrievalReasoningEffort\": {\"kind\": \"low\"}\n",
    "        }\n",
    "        resp = requests.put(f\"{self.search_endpoint}/knowledgebases/{name}?api-version={self.api_version}\",\n",
    "                           headers=self._headers(), json=body)\n",
    "        return self._parse_response(resp)\n",
    "    \n",
    "    def query(self, kb_name: str, query: str):\n",
    "        \"\"\"Query a knowledge base using the retrieve action.\"\"\"\n",
    "        body = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": query}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        resp = requests.post(f\"{self.search_endpoint}/knowledgebases/{kb_name}/retrieve?api-version={self.api_version}\",\n",
    "                            headers=self._headers(), json=body)\n",
    "        return self._parse_response(resp)\n",
    "    \n",
    "    def mcp_url(self, kb_name: str) -> str:\n",
    "        return f\"{self.search_endpoint}/knowledgebases/{kb_name}/mcp?api-version={self.api_version}\"\n",
    "\n",
    "\n",
    "def get_search_token():\n",
    "    return credential.get_token(\"https://search.azure.com/.default\").token\n",
    "\n",
    "iq = FoundryIQClient(SEARCH_ENDPOINT, get_search_token)\n",
    "print(\"‚úÖ Foundry IQ client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "34921075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data source 'apollo-14-research-source' created!\n"
     ]
    }
   ],
   "source": [
    "# Create data source\n",
    "SOURCE_NAME = f\"{INDEX_NAME}-source\"\n",
    "result = iq.create_source(SOURCE_NAME, INDEX_NAME, [\"content\"], \"title\", None)\n",
    "if 'error' not in result:\n",
    "    print(f\"‚úÖ Data source '{SOURCE_NAME}' created!\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create knowledge base\n",
    "KB_NAME = f\"{INDEX_NAME}-kb\"\n",
    "result = iq.create_kb(KB_NAME, [SOURCE_NAME], f\"NASA Technical Reports: {SEARCH_TERM}\", APIM_URL, APIM_KEY, MODEL_NAME)\n",
    "\n",
    "if 'error' not in result:\n",
    "    print(f\"‚úÖ Knowledge base '{KB_NAME}' ready!\")\n",
    "    MCP_URL = iq.mcp_url(KB_NAME)\n",
    "    print(f\"   MCP Endpoint: {MCP_URL[:80]}...\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "987d0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Knowledge base working!\n",
      "   Response messages: 1\n",
      "   References: 1\n",
      "   First response: [{\"ref_id\":0,\"title\":\"Apollo 14 laser ranging retro-reflector experiment - Design certification review report\",\"content\":\"lc:t--. \\\"r. r 1\\nS,\\t DY-SICN VERIFICATIONr\\n3.\\t 1 I_KRR TESY PRO(-,.RAM\\n`,...\n"
     ]
    }
   ],
   "source": [
    "# Test knowledge base\n",
    "test_result = iq.query(KB_NAME, \"What scientific instruments did Apollo 14 deploy?\")\n",
    "if 'error' not in test_result:\n",
    "    # Check for response content\n",
    "    response = test_result.get('response', [])\n",
    "    references = test_result.get('references', [])\n",
    "    print(f\"‚úÖ Knowledge base working!\")\n",
    "    print(f\"   Response messages: {len(response)}\")\n",
    "    print(f\"   References: {len(references)}\")\n",
    "    if response:\n",
    "        for msg in response:\n",
    "            content = msg.get('content', [])\n",
    "            if content:\n",
    "                text = content[0].get('text', '')[:200]\n",
    "                print(f\"   First response: {text}...\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {test_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39def5c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üî¨ Deep Research with Function Calling\n",
    "\n",
    "Now we run **o3-deep-research** using **function calling** instead of MCP.\n",
    "\n",
    "This approach:\n",
    "1. Uses Azure OpenAI Chat Completions API (which works today)\n",
    "2. Implements an **agentic loop** that continues until research is complete\n",
    "3. Provides `search` and `fetch` tools that query Foundry IQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87cf47",
   "metadata": {},
   "source": [
    "## Step 11: Define Research Tools\n",
    "\n",
    "These tools will be called by o3-deep-research during its research process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b7cbd5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research tools defined\n",
      "   - search: Query Foundry IQ knowledge base\n",
      "   - fetch: Get full document content for citation\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Document cache for fetch operations\n",
    "_doc_cache: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "# =============================================================================\n",
    "# TOOL DEFINITIONS (OpenAI Function Calling Schema)\n",
    "# =============================================================================\n",
    "\n",
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"Search NASA Technical Reports for relevant documents. Returns summaries with IDs that can be fetched for full content.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Natural language search query\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"fetch\",\n",
    "            \"description\": \"Fetch complete document content by ID. Use after search to get full details for citation.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Document ID from search results\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# TOOL IMPLEMENTATIONS (Query Foundry IQ)\n",
    "# =============================================================================\n",
    "\n",
    "def tool_search(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Search Foundry IQ knowledge base.\"\"\"\n",
    "    print(f\"   üîç search('{query[:50]}...')\")\n",
    "    \n",
    "    result = iq.query(KB_NAME, query)\n",
    "    \n",
    "    if 'error' in result:\n",
    "        return {\"error\": result['message'], \"results\": []}\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    # Parse the response from Foundry IQ (2025-11-01-preview format)\n",
    "    response = result.get('response', [])\n",
    "    references = result.get('references', [])\n",
    "    \n",
    "    # Extract documents from the response content\n",
    "    for msg in response:\n",
    "        content = msg.get('content', [])\n",
    "        for item in content:\n",
    "            if item.get('type') == 'text':\n",
    "                try:\n",
    "                    # The text is a JSON array of documents\n",
    "                    docs_json = json.loads(item.get('text', '[]'))\n",
    "                    if isinstance(docs_json, list):\n",
    "                        for doc in docs_json[:10]:\n",
    "                            doc_id = str(doc.get('ref_id', hashlib.md5(str(doc).encode()).hexdigest()[:12]))\n",
    "                            parsed = {\n",
    "                                \"id\": doc_id,\n",
    "                                \"title\": doc.get('title', 'Untitled'),\n",
    "                                \"text\": doc.get('content', '')[:500] + \"...\",\n",
    "                                \"url\": f\"https://ntrs.nasa.gov/search\"\n",
    "                            }\n",
    "                            documents.append(parsed)\n",
    "                            # Cache full content for fetch\n",
    "                            _doc_cache[doc_id] = {\n",
    "                                \"id\": doc_id,\n",
    "                                \"title\": doc.get('title', 'Untitled'),\n",
    "                                \"text\": doc.get('content', ''),\n",
    "                                \"url\": parsed['url']\n",
    "                            }\n",
    "                except json.JSONDecodeError:\n",
    "                    # If not JSON, treat as plain text\n",
    "                    pass\n",
    "    \n",
    "    print(f\"      ‚Üí Found {len(documents)} documents\")\n",
    "    return {\"query\": query, \"total_results\": len(documents), \"results\": documents}\n",
    "\n",
    "\n",
    "def tool_fetch(document_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch cached document by ID.\"\"\"\n",
    "    print(f\"   üìÑ fetch('{document_id}')\")\n",
    "    \n",
    "    if document_id not in _doc_cache:\n",
    "        return {\"error\": f\"Document '{document_id}' not found. Use search first.\"}\n",
    "    \n",
    "    doc = _doc_cache[document_id]\n",
    "    print(f\"      ‚Üí Fetched: {doc['title'][:40]}...\")\n",
    "    return doc\n",
    "\n",
    "\n",
    "def execute_tool(name: str, arguments: Dict[str, Any]) -> str:\n",
    "    \"\"\"Execute a tool and return JSON result.\"\"\"\n",
    "    if name == \"search\":\n",
    "        result = tool_search(arguments.get(\"query\", \"\"))\n",
    "    elif name == \"fetch\":\n",
    "        result = tool_fetch(arguments.get(\"document_id\", \"\"))\n",
    "    else:\n",
    "        result = {\"error\": f\"Unknown tool: {name}\"}\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "print(\"‚úÖ Research tools defined\")\n",
    "print(\"   - search: Query Foundry IQ knowledge base\")\n",
    "print(\"   - fetch: Get full document content for citation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489dae2",
   "metadata": {},
   "source": [
    "## Step 12: Initialize Azure OpenAI Clients\n",
    "\n",
    "All API calls go through **APIM gateway** for governance and rate limiting:\n",
    "- **Deep Research**: o3-deep-research via APIM (routed to Norway East backend)\n",
    "- **Final Synthesis**: gpt-4.1-mini via APIM (eastus2 hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize clients - all calls go through APIM gateway\n",
    "# Deep research client uses APIM with API key (routes to Norway East backend)\n",
    "deep_research_client = AzureOpenAI(\n",
    "    azure_endpoint=APIM_URL.replace('/openai', ''),\n",
    "    api_key=APIM_KEY,\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "# Chat client for final report synthesis (gpt-4.1-mini via APIM)\n",
    "chat_client = AzureOpenAI(\n",
    "    azure_endpoint=APIM_URL.replace('/openai', ''),\n",
    "    api_key=APIM_KEY,\n",
    "    api_version=\"2024-10-21\",\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Azure OpenAI clients initialized (via APIM gateway)\")\n",
    "print(f\"   APIM Gateway: {APIM_URL}\")\n",
    "print(f\"   Deep Research Model: {DEEP_RESEARCH_MODEL}\")\n",
    "print(f\"   Synthesis Model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd48ac",
   "metadata": {},
   "source": [
    "## Step 13: Run Deep Research\n",
    "\n",
    "This runs an **agentic loop** where o3-deep-research:\n",
    "1. Analyzes the query and plans research steps\n",
    "2. Calls `search` to find relevant documents\n",
    "3. Calls `fetch` to get full content for promising results\n",
    "4. **gpt-4.1-mini** synthesizes findings into a comprehensive final report\n",
    "\n",
    "> üîí All API calls are routed through **APIM gateway** for governance and rate limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0e5f85c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deep research function ready\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ResearchResult:\n",
    "    \"\"\"Results from deep research.\"\"\"\n",
    "    query: str\n",
    "    iterations: int = 0\n",
    "    tool_calls: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    final_answer: str = \"\"\n",
    "    reasoning_tokens: int = 0\n",
    "    total_tokens: int = 0\n",
    "    duration_seconds: float = 0.0\n",
    "    error: Optional[str] = None\n",
    "\n",
    "\n",
    "def run_deep_research(query: str) -> ResearchResult:\n",
    "    \"\"\"\n",
    "    Run deep research using agentic loop with function calling.\n",
    "    \"\"\"\n",
    "    result = ResearchResult(query=query)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # System prompt for research behavior\n",
    "    system_prompt = f\"\"\"You are a deep research assistant with access to NASA Technical Reports about {SEARCH_TERM}.\n",
    "\n",
    "Your task is to thoroughly research the user's query by:\n",
    "1. Use the 'search' tool to find relevant documents in the knowledge base\n",
    "2. Use the 'fetch' tool to get full content of the most relevant documents\n",
    "3. Analyze and synthesize the information\n",
    "4. Provide a comprehensive, well-cited answer\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "- Search multiple times with different queries to get comprehensive coverage\n",
    "- Fetch all documents that seem relevant before writing your final answer\n",
    "- Include specific facts, dates, figures, and technical details from the documents\n",
    "- Cite your sources using document IDs (e.g., [doc-abc123])\n",
    "- Structure your final answer with clear sections and headers\n",
    "- Be thorough - this is deep research, not a quick summary\n",
    "\n",
    "When you have gathered enough information, provide your final research report.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üî¨ DEEP RESEARCH STARTED\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Query: {query[:80]}...\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        for iteration in range(MAX_RESEARCH_ITERATIONS):\n",
    "            print(f\"\\nüìç Iteration {iteration + 1}/{MAX_RESEARCH_ITERATIONS}\")\n",
    "            \n",
    "            # Call the model\n",
    "            response = deep_research_client.chat.completions.create(\n",
    "                model=DEEP_RESEARCH_MODEL,\n",
    "                messages=messages,\n",
    "                tools=TOOLS\n",
    "            )\n",
    "            \n",
    "            message = response.choices[0].message\n",
    "            result.total_tokens += response.usage.total_tokens if response.usage else 0\n",
    "            \n",
    "            # Check for reasoning tokens (o3 specific)\n",
    "            if response.usage and hasattr(response.usage, 'completion_tokens_details'):\n",
    "                details = response.usage.completion_tokens_details\n",
    "                if details and hasattr(details, 'reasoning_tokens'):\n",
    "                    result.reasoning_tokens += details.reasoning_tokens or 0\n",
    "            \n",
    "            # If no tool calls, we have gathered info - synthesize with gpt-4.1-mini\n",
    "            if not message.tool_calls:\n",
    "                print(\"\\n‚úÖ Research complete, synthesizing final report with gpt-4.1-mini...\")\n",
    "                \n",
    "                # Gather all research context for synthesis\n",
    "                research_context = message.content or \"\"\n",
    "                \n",
    "                # Create synthesis prompt with all gathered information\n",
    "                synthesis_messages = [\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You are an expert research report writer. \n",
    "Based on the research conducted by the deep research model, write a comprehensive, well-structured final report.\n",
    "\n",
    "GUIDELINES:\n",
    "- Structure the report with clear headers and sections\n",
    "- Include specific facts, dates, figures, and technical details\n",
    "- Cite sources using document IDs where available (e.g., [doc-abc123])\n",
    "- Be thorough and comprehensive\n",
    "- Use professional academic writing style\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"Based on this research about {SEARCH_TERM}, write a comprehensive final report:\n",
    "\n",
    "ORIGINAL QUERY:\n",
    "{query}\n",
    "\n",
    "RESEARCH FINDINGS:\n",
    "{research_context}\n",
    "\n",
    "Please synthesize this into a well-organized, comprehensive research report.\"\"\"}\n",
    "                ]\n",
    "                \n",
    "                # Use gpt-4.1-mini for final synthesis\n",
    "                synthesis_response = chat_client.chat.completions.create(\n",
    "                    model=MODEL_NAME,\n",
    "                    messages=synthesis_messages\n",
    "                )\n",
    "                \n",
    "                result.final_answer = synthesis_response.choices[0].message.content or \"\"\n",
    "                if synthesis_response.usage:\n",
    "                    result.total_tokens += synthesis_response.usage.total_tokens\n",
    "                result.iterations = iteration + 1\n",
    "                break\n",
    "            \n",
    "            # Process tool calls\n",
    "            messages.append(message)\n",
    "            \n",
    "            for tool_call in message.tool_calls[:5]:  # Limit per iteration\n",
    "                func_name = tool_call.function.name\n",
    "                func_args = json.loads(tool_call.function.arguments)\n",
    "                \n",
    "                # Execute tool\n",
    "                tool_result = execute_tool(func_name, func_args)\n",
    "                \n",
    "                # Record tool call\n",
    "                result.tool_calls.append({\n",
    "                    \"iteration\": iteration + 1,\n",
    "                    \"tool\": func_name,\n",
    "                    \"arguments\": func_args\n",
    "                })\n",
    "                \n",
    "                # Add tool response to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": tool_result\n",
    "                })\n",
    "            \n",
    "            # Check if max iterations reached\n",
    "            if iteration == MAX_RESEARCH_ITERATIONS - 1:\n",
    "                print(\"\\n‚ö†Ô∏è Max iterations reached, synthesizing final report with gpt-4.1-mini...\")\n",
    "                \n",
    "                # Gather all tool call results for synthesis\n",
    "                # Handle both dict messages and ChatCompletionMessage objects\n",
    "                gathered_info = []\n",
    "                for msg in messages:\n",
    "                    if isinstance(msg, dict):\n",
    "                        if msg.get(\"role\") == \"tool\":\n",
    "                            gathered_info.append(msg.get(\"content\", \"\"))\n",
    "                    # Skip ChatCompletionMessage objects (they don't have tool results)\n",
    "                \n",
    "                # Create synthesis prompt\n",
    "                synthesis_messages = [\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You are an expert research report writer.\n",
    "Based on the research data gathered about {SEARCH_TERM}, write a comprehensive, well-structured final report.\n",
    "\n",
    "GUIDELINES:\n",
    "- Structure the report with clear headers and sections\n",
    "- Include specific facts, dates, figures, and technical details\n",
    "- Cite sources using document IDs where available (e.g., [doc-abc123])\n",
    "- Be thorough and comprehensive\n",
    "- Use professional academic writing style\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"Based on this research about {SEARCH_TERM}, write a comprehensive final report:\n",
    "\n",
    "ORIGINAL QUERY:\n",
    "{query}\n",
    "\n",
    "GATHERED RESEARCH DATA:\n",
    "{chr(10).join(gathered_info[:5])}\n",
    "\n",
    "Please synthesize this into a well-organized, comprehensive research report.\"\"\"}\n",
    "                ]\n",
    "                \n",
    "                # Use gpt-4.1-mini for final synthesis\n",
    "                final_response = chat_client.chat.completions.create(\n",
    "                    model=MODEL_NAME,\n",
    "                    messages=synthesis_messages\n",
    "                )\n",
    "                result.final_answer = final_response.choices[0].message.content or \"\"\n",
    "                result.iterations = iteration + 1\n",
    "                if final_response.usage:\n",
    "                    result.total_tokens += final_response.usage.total_tokens\n",
    "        \n",
    "    except Exception as e:\n",
    "        result.error = str(e)\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "    \n",
    "    result.duration_seconds = round(time.time() - start_time, 2)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üî¨ DEEP RESEARCH COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   Iterations:       {result.iterations}\")\n",
    "    print(f\"   Tool calls:       {len(result.tool_calls)}\")\n",
    "    print(f\"   Total tokens:     {result.total_tokens:,}\")\n",
    "    print(f\"   Reasoning tokens: {result.reasoning_tokens:,}\")\n",
    "    print(f\"   Duration:         {result.duration_seconds}s\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Deep research function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590e374",
   "metadata": {},
   "source": [
    "## Step 14: Execute Deep Research Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f9f1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî¨ DEEP RESEARCH STARTED\n",
      "============================================================\n",
      "Query: Research Apollo 14 comprehensively. \n",
      "I need to understand:\n",
      "1. What was special a...\n",
      "\n",
      "\n",
      "üìç Iteration 1/10\n",
      "   üîç search('Apollo 14 mission overview NASA Technical Reports...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 2/10\n",
      "   üìÑ fetch('0')\n",
      "      ‚Üí Fetched: Apollo 14 mission, 5 day report...\n",
      "\n",
      "üìç Iteration 3/10\n",
      "   üìÑ fetch('1971027929')\n",
      "\n",
      "üìç Iteration 4/10\n",
      "   üîç search('\"Apollo 14 mission, 5 day report\" 1971027929...')\n",
      "      ‚Üí Found 0 documents\n",
      "\n",
      "üìç Iteration 5/10\n",
      "   üîç search('Apollo 14 scientific instruments deployed ALSEP...')\n",
      "      ‚Üí Found 3 documents\n",
      "\n",
      "üìç Iteration 6/10\n",
      "   üîç search('\"Apollo 14 Preliminary Science Report\"...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 7/10\n",
      "   üîç search('Apollo 14 Preliminary Science Report lunar samples...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 8/10\n",
      "   üîç search('\"Apollo 14 Mission Report\" NASA 1971...')\n",
      "      ‚Üí Found 1 documents\n",
      "\n",
      "üìç Iteration 9/10\n",
      "   üìÑ fetch('0')\n",
      "      ‚Üí Fetched: Apollo 14 mission, 5 day report...\n",
      "\n",
      "üìç Iteration 10/10\n",
      "   üìÑ fetch('2')\n",
      "      ‚Üí Fetched: Apollo 14 mission, 5 day report...\n",
      "\n",
      "‚ö†Ô∏è Max iterations reached, synthesizing final report with gpt-4.1-mini...\n",
      "\n",
      "============================================================\n",
      "üî¨ DEEP RESEARCH COMPLETE\n",
      "============================================================\n",
      "   Iterations:       10\n",
      "   Tool calls:       10\n",
      "   Total tokens:     61,129\n",
      "   Reasoning tokens: 3,968\n",
      "   Duration:         87.96s\n"
     ]
    }
   ],
   "source": [
    "# Clear document cache for fresh research\n",
    "_doc_cache.clear()\n",
    "\n",
    "# Define research query\n",
    "research_query = f\"\"\"Research {SEARCH_TERM} comprehensively. \n",
    "I need to understand:\n",
    "1. What was special about this mission?\n",
    "2. What scientific instruments were deployed?\n",
    "3. What were the key findings from the lunar samples?\n",
    "4. Who was the commander and what made him notable?\n",
    "\n",
    "Provide a detailed research report with specific facts, dates, and citations.\"\"\"\n",
    "\n",
    "# Run deep research\n",
    "research_result = run_deep_research(research_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43f7b2",
   "metadata": {},
   "source": [
    "## Step 15: Display Research Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d4219122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"font-family: system-ui; padding: 20px; background: linear-gradient(135deg, #1a1a2e, #16213e); \n",
       "                border-radius: 12px; margin: 10px 0;\">\n",
       "        <h2 style=\"color: #4da6ff; margin: 0 0 15px 0;\">üî¨ Deep Research Results</h2>\n",
       "        <div style=\"display: flex; gap: 20px; flex-wrap: wrap;\">\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #4da6ff; font-weight: bold;\">10</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Iterations</div>\n",
       "            </div>\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #28a745; font-weight: bold;\">10</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Tool Calls</div>\n",
       "            </div>\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #ffc107; font-weight: bold;\">61,129</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Total Tokens</div>\n",
       "            </div>\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #e94560; font-weight: bold;\">87.96s</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Duration</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "## üìÑ Research Report\n",
       "\n",
       "**Final Research Report on Apollo 14 Mission**\n",
       "\n",
       "---\n",
       "\n",
       "**1. Introduction**\n",
       "\n",
       "Apollo 14, the eighth crewed mission in NASA's Apollo program and the third to land humans on the Moon, holds a distinguished place in the annals of lunar exploration. Launched on January 31, 1971, and lasting five days, Apollo 14 was pivotal in continuing scientific exploration of the lunar surface following the technical difficulties of earlier missions. This report provides a comprehensive overview of the mission‚Äôs unique features, scientific instrumentation deployed, key findings from lunar samples, and details about its notable commander.\n",
       "\n",
       "---\n",
       "\n",
       "**2. Unique Aspects and Significance of Apollo 14**\n",
       "\n",
       "Apollo 14 was special primarily for overcoming technical challenges and successfully conducting targeted scientific and exploratory objectives. This mission specifically aimed to explore the Fra Mauro formation, a site of high scientific interest due to its geologic complexity and as the intended landing site for the aborted Apollo 13 mission.\n",
       "\n",
       "Key characteristics of the mission included:\n",
       "\n",
       "- **Targeted Landing:** The lunar module performed a powered descent and landing over revolution 14 in lunar orbit, utilizing descent targeting strategies refined from Apollo 12, adjusting for the challenging terrain at Fra Mauro [doc-1].\n",
       "\n",
       "- **Extended Surface Activities:** Crew executed a series of extravehicular activities (EVAs) involving surface experiments and sample collection. Despite a minor delay in cabin depressurization by roughly 10 minutes, the astronauts succeeded in deploying equipment and collecting extensive scientific data [doc-3].\n",
       "\n",
       "- **Enhanced Mobility and Sampling:** Compared to prior missions, Apollo 14's astronauts noted differences in lunar soil mechanics, including deeper footpad penetration of the lunar module and notable dust behavior during descent below 100 feet altitude [doc-0].\n",
       "\n",
       "The mission recovered critical data to advance lunar geology understanding and refined EVA and equipment deployment procedures in the lunar environment.\n",
       "\n",
       "---\n",
       "\n",
       "**3. Scientific Instruments Deployed**\n",
       "\n",
       "Apollo 14 deployed an array of scientific instruments primarily comprising the Apollo Lunar Surface Experiments Package (ALSEP) and additional specific devices aimed at lunar environmental and geophysical measurements:\n",
       "\n",
       "- **Laser Ranging Retro-reflector (LRRR):** Similar in design to that deployed during Apollo 11, this device reflected laser signals back to Earth, facilitating precise measurements of the Earth-Moon distance by timing the reflection delay [doc-0][doc-0 alt].\n",
       "\n",
       "- **Solar Wind Composition Experiment:** Exposed on the lunar surface for approximately 21 hours, this experiment collected particles emitted by the Sun to analyze the solar wind's elemental and isotopic composition [doc-0].\n",
       "\n",
       "- **Lunar Portable Magnetometer:** This instrument gathered magnetic field data at two separate sites on the lunar surface, yielding valuable insight into the Moon's magnetic environment [doc-0].\n",
       "\n",
       "- **Seismic and Soil Mechanics Tools:** Including a 26.5-inch geophone cable anchor used to probe soil penetration resistance and a trench excavation facilitating stratigraphic sampling of lunar regolith layers [doc-0].\n",
       "\n",
       "- **Communications and Telemetry Systems:** Comprehensive telemetry across multiple frequency bands alongside onboard television equipment transmitted real-time color television of surface operations [doc-2][doc-3].\n",
       "\n",
       "Overall, these instruments were critical for characterizing the lunar environment, surface geophysics, and delivering unprecedented insights into solar-lunar interactions.\n",
       "\n",
       "---\n",
       "\n",
       "**4. Key Findings from Lunar Samples**\n",
       "\n",
       "Apollo 14's sampling activities yielded a diverse collection of regolith and rock materials, revealing new details about lunar geology:\n",
       "\n",
       "- **Soil Mechanics and Stratigraphy:** Investigations exposed three distinct layers near North Triplet Crater:  \n",
       "  1. A dark brown, fine-grained surface layer  \n",
       "  2. An intermediate thin layer predominantly composed of glassy patches  \n",
       "  3. A very light-colored granular material at depth [doc-0]\n",
       "\n",
       "- **Surface Soil Characteristics:** Dust behavior was observed during descent, with lunar soil adhering extensively to clothing and equipment, and footpad penetration depth exceeding previous missions, indicating varied mechanical properties at the Fra Mauro site [doc-0].\n",
       "\n",
       "- **Trench Excavation:** Sampling to a depth of 18 inches revealed mechanically distinct regolith horizons and elucidated the subsurface structure and layering. Notably, collapsing trench walls limited deeper excavation [doc-0].\n",
       "\n",
       "- **Lunar Soil Instrumentation Engagement:** Tests of soil penetration resistance via the geophone cable anchor confirmed variations in mechanical strength, a factor critical for future surface exploration and construction considerations [doc-0].\n",
       "\n",
       "These findings underscored notable geological diversity at the Fra Mauro site compared to earlier Apollo landing locations and contributed to refining models of lunar soil properties.\n",
       "\n",
       "---\n",
       "\n",
       "**5. Apollo 14 Commander: Alan Shepard**\n",
       "\n",
       "Commander Alan B. Shepard Jr. was a defining figure of Apollo 14‚Äôs success and distinction:\n",
       "\n",
       "- **Historical Notability:** Shepard was the first American astronaut to travel into space in 1961 aboard Mercury-Redstone 3 (Freedom 7), marking the United States' breakthrough in human spaceflight.\n",
       "\n",
       "- **Return to Flight:** After a medical condition grounded him for years, Shepard was fully restored to flight status, making Apollo 14 his triumphant return to space.\n",
       "\n",
       "- **Skills and Contributions:** Beyond command duties, Shepard famously performed the first golf shots on the Moon, bringing a human and light-hearted element to lunar exploration while demonstrating crew adaptability [doc-3].\n",
       "\n",
       "- **Leadership:** His experience and calm demeanor helped overcome mission delays and ensured smooth execution of surface EVA tasks and equipment deployment.\n",
       "\n",
       "Shepard remains a celebrated astronaut, underpinning Apollo 14 with both technical expertise and historical significance.\n",
       "\n",
       "---\n",
       "\n",
       "**6. Conclusion**\n",
       "\n",
       "Apollo 14 was a landmark mission that exemplified NASA‚Äôs resilience and scientific ambition during the Apollo era. It combined meticulous planning, advanced instrumentation deployment, and skilled astronaut leadership to achieve vital exploration and research milestones on the Moon. The comprehensive scientific data and lunar samples gathered expanded knowledge of the Moon‚Äôs geology, environment, and space weather influences. Commander Alan Shepard‚Äôs pivotal role marked a triumphant chapter in human spaceflight history.\n",
       "\n",
       "---\n",
       "\n",
       "**References**\n",
       "\n",
       "- Apollo 14 Mission, 5 Day Report, NASA Technical Reports [doc-0], [doc-3], [doc-4]  \n",
       "- Apollo 14 (mission H-3) Baseline Mission Profile, NASA Technical Reports [doc-1]  \n",
       "- Apollo/Saturn 5 Consolidated Instrumentation Plan for AS-509 /Apollo 14/, NASA Technical Reports [doc-2]  \n",
       "- Apollo 14 Laser Ranging Retro-reflector Experiment - Design Certification Review Report, NASA Technical Reports [doc-0 alt]\n",
       "\n",
       "*Note: Document identifiers correspond to source data indexed from NASA Technical Report Server (NTRS).*\n",
       "\n",
       "---\n",
       "\n",
       "**Prepared by: [Your Name]  \n",
       "Date: [Current Date]**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the research report\n",
    "if research_result.error:\n",
    "    display(HTML(f'<div style=\"background:#ffdddd;padding:15px;border-radius:8px;\">'\n",
    "                 f'<h3>‚ùå Research Error</h3><p>{research_result.error}</p></div>'))\n",
    "else:\n",
    "    # Summary card\n",
    "    html = f'''\n",
    "    <div style=\"font-family: system-ui; padding: 20px; background: linear-gradient(135deg, #1a1a2e, #16213e); \n",
    "                border-radius: 12px; margin: 10px 0;\">\n",
    "        <h2 style=\"color: #4da6ff; margin: 0 0 15px 0;\">üî¨ Deep Research Results</h2>\n",
    "        <div style=\"display: flex; gap: 20px; flex-wrap: wrap;\">\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #4da6ff; font-weight: bold;\">{research_result.iterations}</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Iterations</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #28a745; font-weight: bold;\">{len(research_result.tool_calls)}</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Tool Calls</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #ffc107; font-weight: bold;\">{research_result.total_tokens:,}</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Total Tokens</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #e94560; font-weight: bold;\">{research_result.duration_seconds}s</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Duration</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    '''\n",
    "    display(HTML(html))\n",
    "    \n",
    "    # Research report\n",
    "    display(Markdown(\"---\\n## üìÑ Research Report\\n\\n\" + research_result.final_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d718151",
   "metadata": {},
   "source": [
    "## Step 16: Analyze Tool Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d9f9305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üîß Tool Call Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search calls: 6\n",
      "Fetch calls:  4\n",
      "\n",
      "Search queries:\n",
      "  1. Apollo 14 mission overview NASA Technical Reports...\n",
      "  2. \"Apollo 14 mission, 5 day report\" 1971027929...\n",
      "  3. Apollo 14 scientific instruments deployed ALSEP...\n",
      "  4. \"Apollo 14 Preliminary Science Report\"...\n",
      "  5. Apollo 14 Preliminary Science Report lunar samples analysis findings...\n",
      "  6. \"Apollo 14 Mission Report\" NASA 1971...\n",
      "\n",
      "Documents fetched: 4\n"
     ]
    }
   ],
   "source": [
    "# Show tool call breakdown\n",
    "if research_result.tool_calls:\n",
    "    display(Markdown(\"### üîß Tool Call Summary\"))\n",
    "    \n",
    "    search_calls = [t for t in research_result.tool_calls if t['tool'] == 'search']\n",
    "    fetch_calls = [t for t in research_result.tool_calls if t['tool'] == 'fetch']\n",
    "    \n",
    "    print(f\"Search calls: {len(search_calls)}\")\n",
    "    print(f\"Fetch calls:  {len(fetch_calls)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Search queries:\")\n",
    "    for i, call in enumerate(search_calls, 1):\n",
    "        query = call['arguments'].get('query', 'N/A')\n",
    "        print(f\"  {i}. {query[:70]}...\")\n",
    "    \n",
    "    print(f\"\\nDocuments fetched: {len(fetch_calls)}\")\n",
    "else:\n",
    "    print(\"No tool calls recorded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432fd0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've completed the **Deep Research** lab using:\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **o3-deep-research** | Advanced reasoning model with multi-step tool use |\n",
    "| **gpt-4.1-mini** | Final report synthesis (cost-effective) |\n",
    "| **APIM Gateway** | All API calls routed through gateway for governance |\n",
    "| **Foundry IQ** | Knowledge base for NASA Technical Reports |\n",
    "| **Agentic Loop** | Iterative search ‚Üí fetch ‚Üí synthesize pattern |\n",
    "\n",
    "### Architecture Benefits\n",
    "\n",
    "- ‚úÖ **All calls via APIM** - centralized governance, rate limiting, and observability\n",
    "- ‚úÖ **Multi-region Landing Zone** pattern (Norway East for o3-deep-research)\n",
    "- ‚úÖ **Cost optimization** - o3-deep-research for reasoning, gpt-4.1-mini for synthesis\n",
    "- ‚úÖ **Foundry IQ integration** for enterprise knowledge bases\n",
    "- ‚úÖ **Citation-rich reports** with source tracking\n",
    "\n",
    "### Configuration\n",
    "\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| MAX_RESEARCH_ITERATIONS | 10 |\n",
    "| Deep Research Model | o3-deep-research |\n",
    "| Synthesis Model | gpt-4.1-mini |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different `SEARCH_TERM` values (\"Mars\", \"Voyager\", \"Space Shuttle\")\n",
    "- Adjust `MAX_RESEARCH_ITERATIONS` for more/less thorough research\n",
    "- Add more tools (web search, code execution)\n",
    "- Monitor usage via APIM analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf3ade",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69fa0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete resources\n",
    "# !az group delete -n \"{RG}\" --yes --no-wait\n",
    "# print(\"‚úÖ Cleanup initiated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
