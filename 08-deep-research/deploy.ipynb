{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd362c9a",
   "metadata": {},
   "source": [
    "# Lab 8: Deep Research with NASA Technical Reports\n",
    "\n",
    "Use **o3-deep-research** with **function calling** to research NASA NTRS documents!\n",
    "\n",
    "## What is o3-deep-research?\n",
    "\n",
    "The `o3-deep-research` model is designed for **advanced research tasks**. It can:\n",
    "- Browse, analyze, and synthesize information from **hundreds of sources**\n",
    "- Produce **comprehensive, citation-rich reports**\n",
    "- Use **multi-step reasoning** with tools\n",
    "- Run **code for complex analysis**\n",
    "\n",
    "| Standard Chat | o3-deep-research |\n",
    "|--------------|------------------|\n",
    "| Single model call | Multi-step reasoning with tool use |\n",
    "| No tool loops | **Agentic loop** with search/fetch |\n",
    "| Instant response | Extended reasoning for complex queries |\n",
    "| Generic answers | **Cited, sourced** research reports |\n",
    "\n",
    "## Data Source: NASA NTRS\n",
    "\n",
    "We download **NASA's Technical Reports Server (NTRS)** public metadata:\n",
    "- 800,000+ NASA technical documents\n",
    "- Original mission reports, scientific papers, technical memoranda\n",
    "- Filter for specific topics (default: **Apollo 14**)\n",
    "- Index into **Foundry IQ** knowledge base\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed **Lab 1a** (Landing Zone) - provides APIM gateway, models (including o3-deep-research), and embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a0c6e",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdabe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas requests azure-identity azure-search-documents pypdf matplotlib ijson openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee45c1",
   "metadata": {},
   "source": [
    "## Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, Dict, List, Any\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Modify these for your use case\n",
    "# =============================================================================\n",
    "\n",
    "SEARCH_TERM = \"Apollo 14\"      # What to research\n",
    "MAX_PDF_SIZE_MB = 100          # Maximum total PDF download size\n",
    "MAX_RESEARCH_ITERATIONS = 25   # Maximum tool call iterations\n",
    "\n",
    "# Resource names for this lab (Azure AI Search for Foundry IQ)\n",
    "RG = \"deep-research-lab-rg\"\n",
    "LOCATION = \"eastus2\"\n",
    "\n",
    "# =============================================================================\n",
    "# Load environment from Lab 1a\n",
    "# =============================================================================\n",
    "\n",
    "env_path = Path(\"../.env\")\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        if '=' in line and not line.startswith('#'):\n",
    "            key, value = line.split('=', 1)\n",
    "            os.environ[key.strip()] = value.strip()\n",
    "\n",
    "APIM_URL = os.environ.get(\"APIM_URL\", \"\")\n",
    "APIM_KEY = os.environ.get(\"APIM_KEY\", \"\")\n",
    "AI_ENDPOINT = os.environ.get(\"AI_ENDPOINT\", \"\")\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"gpt-4.1-mini\")\n",
    "EMBEDDING_MODEL = os.environ.get(\"EMBEDDING_MODEL\", \"text-embedding-3-large\")\n",
    "DEEP_RESEARCH_MODEL = os.environ.get(\"DEEP_RESEARCH_MODEL\", \"o3-deep-research\")\n",
    "\n",
    "# Get current user\n",
    "PRINCIPAL_ID = subprocess.run(\n",
    "    'az ad signed-in-user show --query id -o tsv',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "\n",
    "# Verify configuration\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIGURATION STATUS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not APIM_URL or not APIM_KEY:\n",
    "    print(\"  [WARN] Missing APIM_URL or APIM_KEY in .env file!\")\n",
    "    print(\"         Please complete Lab 1a first\")\n",
    "else:\n",
    "    print(\"[OK] Azure Configuration Loaded from Lab 1a\")\n",
    "    print(f\"       APIM Gateway:     {APIM_URL[:50]}...\")\n",
    "    print(f\"       Chat Model:       {MODEL_NAME}\")\n",
    "    print(f\"       Embedding Model:  {EMBEDDING_MODEL}\")\n",
    "    print(f\"       Deep Research:    {DEEP_RESEARCH_MODEL}\")\n",
    "\n",
    "print()\n",
    "print(f\"Research Term: {SEARCH_TERM}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee3c3a",
   "metadata": {},
   "source": [
    "## Step 3: Deploy Infrastructure\n",
    "\n",
    "This creates:\n",
    "- **Azure AI Search**: For Foundry IQ knowledge bases\n",
    "\n",
    "The o3-deep-research model was already deployed in **Lab 1a** (Landing Zone) and is accessed via APIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e800e5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\n",
      "----------  --------------------\n",
      "eastus2     deep-research-lab-rg\n"
     ]
    }
   ],
   "source": [
    "!az group create -n \"{RG}\" -l \"{LOCATION}\" -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22d28ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KName    State      Timestamp                         Mode         ResourceGroup\n",
      "------  ---------  --------------------------------  -----------  --------------------\n",
      "spoke   Succeeded  2026-01-25T10:36:59.174724+00:00  Incremental  deep-research-lab-rg\n"
     ]
    }
   ],
   "source": [
    "# Deploy Azure AI Search for Foundry IQ knowledge bases\n",
    "!az deployment group create -g \"{RG}\" --template-file spoke.bicep \\\n",
    "    -p deployerPrincipalId=\"{PRINCIPAL_ID}\" \\\n",
    "    -o table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499153a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get deployment outputs\n",
    "outputs = json.loads(subprocess.run(\n",
    "    f'az deployment group show -g \"{RG}\" -n spoke --query properties.outputs -o json',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout)\n",
    "\n",
    "SEARCH_ENDPOINT = outputs['searchEndpoint']['value']\n",
    "SEARCH_NAME = outputs['searchName']['value']\n",
    "\n",
    "print(f\"Deployment Complete!\")\n",
    "print(f\"   Search Service:     {SEARCH_NAME}\")\n",
    "print(f\"   Search Endpoint:    {SEARCH_ENDPOINT}\")\n",
    "print(f\"   Deep Research via:  APIM Gateway (Lab 1a)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f80b131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RBAC permissions ready!\n"
     ]
    }
   ],
   "source": [
    "# Wait for RBAC propagation\n",
    "for i in range(60, 0, -10):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"‚è≥ Waiting for RBAC to propagate... {i}s\")\n",
    "    time.sleep(10)\n",
    "clear_output(wait=True)\n",
    "print(\"‚úÖ RBAC permissions ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13903436",
   "metadata": {},
   "source": [
    "## Step 4: Download NASA NTRS Metadata\n",
    "\n",
    "Download the full NASA Technical Reports Server metadata (~2GB compressed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f94001bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadata already exists: ntrs_data/ntrs-public-metadata.json.gz (398.9 MB)\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "NTRS_METADATA_URL = \"https://www.sti.nasa.gov/docs/ntrs-public-metadata.json.gz\"\n",
    "DATA_DIR = Path(\"./ntrs_data\")\n",
    "METADATA_FILE = DATA_DIR / \"ntrs-public-metadata.json.gz\"\n",
    "PDF_DIR = DATA_DIR / \"pdfs\"\n",
    "\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "PDF_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Download metadata if not present\n",
    "if not METADATA_FILE.exists():\n",
    "    print(f\"üì• Downloading NTRS metadata (~2GB compressed)...\")\n",
    "    !curl -L -o \"{METADATA_FILE}\" \"{NTRS_METADATA_URL}\" --progress-bar\n",
    "    print(f\"‚úÖ Downloaded to {METADATA_FILE}\")\n",
    "else:\n",
    "    size_mb = METADATA_FILE.stat().st_size / (1024 * 1024)\n",
    "    print(f\"‚úÖ Metadata already exists: {METADATA_FILE} ({size_mb:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300beae4",
   "metadata": {},
   "source": [
    "## Step 5: Filter Documents by Search Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61359404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Streaming metadata for 'Apollo 14'...\n",
      "   Scanned 550,000 docs, found 451 matches...\n",
      "‚úÖ Found 461 documents matching 'Apollo 14'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19740072936</td>\n",
       "      <td>Apollo 14 (mission H-3) Baseline Mission Profile</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19710001731</td>\n",
       "      <td>Apollo operations handbook, extravehicular mob...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19710004668</td>\n",
       "      <td>Apollo/Saturn 5 consolidated instrumentation p...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19710005842</td>\n",
       "      <td>Apollo 14 /AS-509/ operational trajectory for ...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19710010322</td>\n",
       "      <td>Apollo 14 laser ranging retro-reflector experi...</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19950023897</td>\n",
       "      <td>Apollo 14: Shepard Hitting Golf Ball on Moon</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19710021481</td>\n",
       "      <td>Preliminary geologic investigations of the Apo...</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19710021482</td>\n",
       "      <td>Soil mechanics experiment</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19710021486</td>\n",
       "      <td>Suprathermal ion detector experiment /lunar io...</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19710027929</td>\n",
       "      <td>Apollo 14 mission, 5 day report</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  year\n",
       "0  19740072936   Apollo 14 (mission H-3) Baseline Mission Profile  1969\n",
       "1  19710001731  Apollo operations handbook, extravehicular mob...  1970\n",
       "2  19710004668  Apollo/Saturn 5 consolidated instrumentation p...  1970\n",
       "3  19710005842  Apollo 14 /AS-509/ operational trajectory for ...  1970\n",
       "4  19710010322  Apollo 14 laser ranging retro-reflector experi...  1970\n",
       "5  19950023897       Apollo 14: Shepard Hitting Golf Ball on Moon  1970\n",
       "6  19710021481  Preliminary geologic investigations of the Apo...  1971\n",
       "7  19710021482                          Soil mechanics experiment  1971\n",
       "8  19710021486  Suprathermal ion detector experiment /lunar io...  1971\n",
       "9  19710027929                    Apollo 14 mission, 5 day report  1971"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ijson\n",
    "\n",
    "print(f\"üîç Streaming metadata for '{SEARCH_TERM}'...\")\n",
    "\n",
    "search_lower = SEARCH_TERM.lower()\n",
    "filtered_docs = []\n",
    "doc_count = 0\n",
    "\n",
    "with gzip.open(METADATA_FILE, 'rb') as f:\n",
    "    for doc_id, doc in ijson.kvitems(f, ''):\n",
    "        doc_count += 1\n",
    "        if doc_count % 50000 == 0:\n",
    "            print(f\"   Scanned {doc_count:,} docs, found {len(filtered_docs)} matches...\", end='\\r')\n",
    "        \n",
    "        title = doc.get('title', '') or ''\n",
    "        abstract = doc.get('abstract', '') or ''\n",
    "        \n",
    "        if search_lower in title.lower() or search_lower in abstract.lower():\n",
    "            doc['ntrs_id'] = doc_id\n",
    "            filtered_docs.append(doc)\n",
    "\n",
    "print(f\"\\n‚úÖ Found {len(filtered_docs)} documents matching '{SEARCH_TERM}'\")\n",
    "\n",
    "if filtered_docs:\n",
    "    df = pd.DataFrame([{\n",
    "        \"id\": d.get('ntrs_id'),\n",
    "        \"title\": d.get('title', 'N/A')[:60],\n",
    "        \"year\": d.get('publications', [{}])[0].get('publicationDate', '')[:4] if d.get('publications') else 'N/A',\n",
    "    } for d in filtered_docs[:10]])\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8637294",
   "metadata": {},
   "source": [
    "## Step 6: Download PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9641fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading PDFs (max 100 MB total)...\n",
      "  19740072936: Apollo 14 (mission H-3) Baseline Mission... ‚úÖ (810.9 KB) [0.8/100 MB]\n",
      "  19710001731: Apollo operations handbook, extravehicul... ‚úÖ (7576.6 KB) [8.2/100 MB]\n",
      "  19710004668: Apollo/Saturn 5 consolidated instrumenta... ‚úÖ (3098.6 KB) [11.2/100 MB]\n",
      "  19710005842: Apollo 14 /AS-509/ operational trajector... ‚úÖ (22696.0 KB) [33.4/100 MB]\n",
      "  19710010322: Apollo 14 laser ranging retro-reflector ... ‚úÖ (19579.8 KB) [52.5/100 MB]\n",
      "  19950023897: Apollo 14: Shepard Hitting Golf Ball on ... (no PDF)\n",
      "  19710021481: Preliminary geologic investigations of t... (no PDF)\n",
      "  19710021482: Soil mechanics experiment... (no PDF)\n",
      "  19710021486: Suprathermal ion detector experiment /lu... (no PDF)\n",
      "  19710027929: Apollo 14 mission, 5 day report... ‚úÖ (1119.4 KB) [53.6/100 MB]\n",
      "  19710055248: Ar 40/Ar 39 ages from Fra Mauro... (no PDF)\n",
      "  19710058684: Chemical composition of Apollo 14 soils ... (no PDF)\n",
      "  19710061141: Ages of crystalline rocks from Fra Mauro... (no PDF)\n",
      "  19710061288: Medical results of Apollo 14 - Implicati... (no PDF)\n",
      "  19720007220: Apollo 14 composite casting demonstratio... ‚úÖ (46911.3 KB) [99.4/100 MB]\n",
      "  19720010767: Apollo 14 lunar photography.  Part 1:  D... ‚úÖ (1406.5 KB) [100.8/100 MB]\n",
      "\n",
      "‚úÖ Downloaded 8 PDFs (100.8 MB)\n"
     ]
    }
   ],
   "source": [
    "NTRS_BASE = \"https://ntrs.nasa.gov\"\n",
    "NTRS_API_BASE = f\"{NTRS_BASE}/api\"\n",
    "\n",
    "def get_downloads(ntrs_id: str) -> list:\n",
    "    \"\"\"Get available PDF downloads for a document.\"\"\"\n",
    "    try:\n",
    "        resp = requests.get(f\"{NTRS_API_BASE}/citations/{ntrs_id}\", timeout=30)\n",
    "        if resp.ok:\n",
    "            return [d for d in resp.json().get('downloads', []) \n",
    "                    if d.get('mimetype', '').lower() == 'application/pdf']\n",
    "    except: \n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def download_pdf(ntrs_id: str, dl: dict) -> tuple:\n",
    "    \"\"\"Download a PDF and return (filepath, size).\"\"\"\n",
    "    try:\n",
    "        rel_path = dl.get('links', {}).get('pdf')\n",
    "        if rel_path:\n",
    "            pdf_url = f\"{NTRS_BASE}{rel_path}\"\n",
    "        else:\n",
    "            pdf_url = f\"{NTRS_API_BASE}/citations/{ntrs_id}/downloads/{dl.get('name', ntrs_id + '.pdf')}\"\n",
    "        \n",
    "        filepath = PDF_DIR / f\"{ntrs_id}_{dl.get('name', 'doc.pdf').replace('.pdf', '')}.pdf\"\n",
    "        if filepath.exists():\n",
    "            return filepath, filepath.stat().st_size\n",
    "        \n",
    "        resp = requests.get(pdf_url, timeout=120, stream=True)\n",
    "        if resp.ok and 'application/pdf' in resp.headers.get('content-type', ''):\n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in resp.iter_content(8192):\n",
    "                    f.write(chunk)\n",
    "            return filepath, filepath.stat().st_size\n",
    "    except:\n",
    "        pass\n",
    "    return None, 0\n",
    "\n",
    "print(f\"üì• Downloading PDFs (max {MAX_PDF_SIZE_MB} MB total)...\")\n",
    "downloaded = []\n",
    "total_bytes = 0\n",
    "\n",
    "for doc in filtered_docs:\n",
    "    if total_bytes >= MAX_PDF_SIZE_MB * 1024 * 1024:\n",
    "        break\n",
    "    \n",
    "    ntrs_id = doc['ntrs_id']\n",
    "    title = doc.get('title', 'N/A')[:40]\n",
    "    print(f\"  {ntrs_id}: {title}...\", end=\" \")\n",
    "    \n",
    "    downloads = get_downloads(ntrs_id)\n",
    "    if not downloads:\n",
    "        print(\"(no PDF)\")\n",
    "        continue\n",
    "    \n",
    "    filepath, sz = download_pdf(ntrs_id, downloads[0])\n",
    "    if filepath:\n",
    "        total_bytes += sz\n",
    "        downloaded.append({\n",
    "            'ntrs_id': ntrs_id,\n",
    "            'title': doc.get('title', ''),\n",
    "            'abstract': doc.get('abstract', ''),\n",
    "            'authors': [a.get('name', '') for a in doc.get('authorAffiliations', [])],\n",
    "            'year': doc.get('publications', [{}])[0].get('publicationDate', '')[:4] if doc.get('publications') else '',\n",
    "            'filepath': filepath\n",
    "        })\n",
    "        print(f\"‚úÖ ({sz/1024:.1f} KB) [{total_bytes/1024/1024:.1f}/{MAX_PDF_SIZE_MB} MB]\")\n",
    "    else:\n",
    "        print(\"(error)\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(f\"\\n‚úÖ Downloaded {len(downloaded)} PDFs ({total_bytes/1024/1024:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf2fe8",
   "metadata": {},
   "source": [
    "## Step 7: Extract Text from PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19802fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Extracting text from PDFs...\n",
      "  19740072936_19740072936.pdf... ‚úÖ (22,884 chars)\n",
      "  19710001731_19710001731.pdf... ‚úÖ (39,142 chars)\n",
      "  19710004668_19710004668.pdf... ‚úÖ (37,973 chars)\n",
      "  19710005842_19710005842.pdf... ‚úÖ (53,520 chars)\n",
      "  19710010322_19710010322.pdf... ‚úÖ (35,832 chars)\n",
      "  19710027929_19710027929.pdf... ‚úÖ (38,249 chars)\n",
      "  19720007220_19720007220.pdf... ‚úÖ (72,354 chars)\n",
      "  19720010767_19720010767.pdf... ‚úÖ (35,262 chars)\n",
      "\n",
      "‚úÖ Extracted text from 8 documents\n"
     ]
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "def extract_text(filepath: Path, max_pages: int = 50) -> str:\n",
    "    \"\"\"Extract text from PDF.\"\"\"\n",
    "    try:\n",
    "        reader = PdfReader(filepath)\n",
    "        return \"\\n\\n\".join([p.extract_text() or \"\" for p in reader.pages[:max_pages]])\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"üìÑ Extracting text from PDFs...\")\n",
    "documents = []\n",
    "\n",
    "for doc in downloaded:\n",
    "    print(f\"  {doc['filepath'].name}...\", end=\" \")\n",
    "    text = extract_text(doc['filepath'])\n",
    "    if text and len(text) > 100:\n",
    "        full_text = f\"\"\"Title: {doc['title']}\n",
    "Authors: {', '.join(doc['authors'])}\n",
    "Year: {doc['year']}\n",
    "\n",
    "Abstract:\n",
    "{doc['abstract']}\n",
    "\n",
    "Full Text:\n",
    "{text}\"\"\"\n",
    "        documents.append({\n",
    "            'ntrs_id': doc['ntrs_id'], \n",
    "            'title': doc['title'], \n",
    "            'text': full_text, \n",
    "            'year': doc['year'], \n",
    "        })\n",
    "        print(f\"‚úÖ ({len(text):,} chars)\")\n",
    "    else:\n",
    "        print(\"-\")\n",
    "\n",
    "print(f\"\\n‚úÖ Extracted text from {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d4659",
   "metadata": {},
   "source": [
    "## Step 8: Create Azure AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10b1c443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index 'apollo-14-research' created!\n"
     ]
    }
   ],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex, SearchField, SearchFieldDataType,\n",
    "    SemanticConfiguration, SemanticField, SemanticPrioritizedFields, SemanticSearch,\n",
    "    VectorSearch, HnswAlgorithmConfiguration, VectorSearchProfile\n",
    ")\n",
    "from azure.search.documents import SearchIndexingBufferedSender\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "index_client = SearchIndexClient(endpoint=SEARCH_ENDPOINT, credential=credential)\n",
    "\n",
    "INDEX_NAME = f\"{SEARCH_TERM.lower().replace(' ', '-')}-research\"\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    fields=[\n",
    "        SearchField(name=\"id\", type=\"Edm.String\", key=True, filterable=True),\n",
    "        SearchField(name=\"parent_id\", type=\"Edm.String\", filterable=True),\n",
    "        SearchField(name=\"chunk_index\", type=\"Edm.Int32\", sortable=True),\n",
    "        SearchField(name=\"ntrs_id\", type=\"Edm.String\", filterable=True),\n",
    "        SearchField(name=\"title\", type=\"Edm.String\", searchable=True),\n",
    "        SearchField(name=\"year\", type=\"Edm.String\", filterable=True, facetable=True),\n",
    "        SearchField(name=\"subjects\", type=\"Collection(Edm.String)\", filterable=True, facetable=True),\n",
    "        SearchField(name=\"content\", type=\"Edm.String\", searchable=True),\n",
    "        SearchField(name=\"content_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                    vector_search_dimensions=3072, vector_search_profile_name=\"vector-profile\", searchable=True),\n",
    "    ],\n",
    "    vector_search=VectorSearch(\n",
    "        algorithms=[HnswAlgorithmConfiguration(name=\"hnsw-algo\")],\n",
    "        profiles=[VectorSearchProfile(name=\"vector-profile\", algorithm_configuration_name=\"hnsw-algo\")]\n",
    "    ),\n",
    "    semantic_search=SemanticSearch(\n",
    "        default_configuration_name=\"semantic-config\",\n",
    "        configurations=[SemanticConfiguration(name=\"semantic-config\", prioritized_fields=SemanticPrioritizedFields(\n",
    "            content_fields=[SemanticField(field_name=\"content\")], title_field=SemanticField(field_name=\"title\")\n",
    "        ))]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Retry loop for RBAC propagation\n",
    "for attempt in range(6):\n",
    "    try:\n",
    "        index_client.create_or_update_index(index)\n",
    "        print(f\"‚úÖ Index '{INDEX_NAME}' created!\")\n",
    "        break\n",
    "    except HttpResponseError as e:\n",
    "        if 'Forbidden' in str(e) and attempt < 5:\n",
    "            print(f\"   RBAC not ready, waiting 30s... (attempt {attempt+1}/6)\")\n",
    "            time.sleep(30)\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e549fb",
   "metadata": {},
   "source": [
    "## Step 9: Generate Embeddings & Upload to Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76ac9b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding model working! Dimension: 3072\n",
      "\n",
      "üìÑ Chunking 8 documents...\n",
      "  [1/8] Apollo 14 (mission H-3) Baseline Mi... ‚Üí 7 chunks\n",
      "\n",
      "  [2/8] Apollo operations handbook, extrave... ‚Üí 14 chunks\n",
      "\n",
      "  [3/8] Apollo/Saturn 5 consolidated instru... ‚Üí 14 chunks\n",
      "\n",
      "  [4/8] Apollo 14 /AS-509/ operational traj... ‚Üí 19 chunks\n",
      "\n",
      "  [5/8] Apollo 14 laser ranging retro-refle... ‚Üí 13 chunks\n",
      "\n",
      "  [6/8] Apollo 14 mission, 5 day report... ‚Üí 14 chunks\n",
      "\n",
      "  [7/8] Apollo 14 composite casting demonst... ‚Üí 30 chunks\n",
      "\n",
      "  [8/8] Apollo 14 lunar photography.  Part ... ‚Üí 14 chunks\n",
      "\n",
      "\n",
      "‚úÖ Created 125 chunks from 8 documents\n",
      "\n",
      "üì§ Uploading to Azure AI Search...\n",
      "‚úÖ Uploaded 125 chunks to index 'apollo-14-research'!\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SIZE = 4000\n",
    "CHUNK_OVERLAP = 400\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> list[str]:\n",
    "    \"\"\"Split text into chunks at semantic boundaries.\"\"\"\n",
    "    if len(text) <= chunk_size:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    start = 0\n",
    "    \n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        \n",
    "        if end >= len(text):\n",
    "            chunks.append(text[start:])\n",
    "            break\n",
    "        \n",
    "        chunk = text[start:end]\n",
    "        split_pos = chunk.rfind('\\n\\n')\n",
    "        if split_pos > chunk_size * 0.5:\n",
    "            end = start + split_pos + 2\n",
    "        else:\n",
    "            for pattern in ['. ', '.\\n', '? ', '! ']:\n",
    "                pos = chunk.rfind(pattern)\n",
    "                if pos > chunk_size * 0.5:\n",
    "                    split_pos = pos\n",
    "                    break\n",
    "            if split_pos > chunk_size * 0.5:\n",
    "                end = start + split_pos + 2\n",
    "            else:\n",
    "                split_pos = chunk.rfind(' ')\n",
    "                if split_pos > 0:\n",
    "                    end = start + split_pos + 1\n",
    "        \n",
    "        chunks.append(text[start:end].strip())\n",
    "        start = end - overlap\n",
    "    \n",
    "    return [c for c in chunks if c.strip()]\n",
    "\n",
    "def get_embedding(text: str, max_chars: int = 8191, max_retries: int = 25) -> list:\n",
    "    \"\"\"Get embedding with exponential backoff.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        resp = requests.post(\n",
    "            f\"{APIM_URL}/deployments/{EMBEDDING_MODEL}/embeddings\",\n",
    "            headers={\"api-key\": APIM_KEY, \"Content-Type\": \"application/json\"},\n",
    "            json={\"input\": text[:max_chars], \"model\": EMBEDDING_MODEL}\n",
    "        )\n",
    "        if resp.status_code == 429 :\n",
    "            wait = (2 ** attempt) + 1\n",
    "            print(f\"‚è≥ Rate limited, waiting {wait}s...\", end=\" \", flush=True)\n",
    "            time.sleep(wait)\n",
    "            continue\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()[\"data\"][0][\"embedding\"]\n",
    "    raise Exception(\"Max retries exceeded\")\n",
    "\n",
    "# Test embedding\n",
    "test_emb = get_embedding(\"Apollo 14 lunar mission\")\n",
    "print(f\"‚úÖ Embedding model working! Dimension: {len(test_emb)}\")\n",
    "\n",
    "# Generate chunks and embeddings\n",
    "print(f\"\\nüìÑ Chunking {len(documents)} documents...\")\n",
    "search_docs = []\n",
    "total_chunks = 0\n",
    "\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    chunks = chunk_text(doc['text'])\n",
    "    print(f\"  [{doc_idx+1}/{len(documents)}] {doc['title'][:35]}... ‚Üí {len(chunks)} chunks\")\n",
    "    \n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        embed_text = f\"{doc['title']}\\n\\n{chunk}\"\n",
    "        \n",
    "        search_docs.append({\n",
    "            \"id\": f\"{doc_idx+1}_{chunk_idx}\",\n",
    "            \"parent_id\": str(doc_idx + 1),\n",
    "            \"chunk_index\": chunk_idx,\n",
    "            \"ntrs_id\": doc['ntrs_id'],\n",
    "            \"title\": doc['title'],\n",
    "            \"year\": doc['year'],\n",
    "            \"content\": chunk,\n",
    "            \"content_vector\": get_embedding(embed_text)\n",
    "        })\n",
    "        total_chunks += 1\n",
    "        time.sleep(0.5)\n",
    "    print()\n",
    "\n",
    "print(f\"\\n‚úÖ Created {total_chunks} chunks from {len(documents)} documents\")\n",
    "\n",
    "# Upload\n",
    "print(f\"\\nüì§ Uploading to Azure AI Search...\")\n",
    "with SearchIndexingBufferedSender(endpoint=SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=credential) as sender:\n",
    "    sender.upload_documents(documents=search_docs)\n",
    "\n",
    "print(f\"‚úÖ Uploaded {len(search_docs)} chunks to index '{INDEX_NAME}'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efb6c8a",
   "metadata": {},
   "source": [
    "## Step 10: Create Foundry IQ Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74cfeefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Foundry IQ client initialized\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FOUNDRY IQ CLIENT\n",
    "# =============================================================================\n",
    "\n",
    "class FoundryIQClient:\n",
    "    \"\"\"Client for Foundry IQ knowledge bases.\"\"\"\n",
    "    \n",
    "    def __init__(self, search_endpoint: str, get_token):\n",
    "        self.search_endpoint = search_endpoint.rstrip('/')\n",
    "        self.get_token = get_token\n",
    "        self.api_version = \"2025-11-01-preview\"\n",
    "    \n",
    "    def _headers(self):\n",
    "        return {\"Authorization\": f\"Bearer {self.get_token()}\", \"Content-Type\": \"application/json\"}\n",
    "    \n",
    "    def _parse_response(self, resp):\n",
    "        \"\"\"Parse response, handling empty bodies for 2xx responses.\"\"\"\n",
    "        if resp.ok:\n",
    "            if resp.text:\n",
    "                return resp.json()\n",
    "            else:\n",
    "                return {\"status\": \"success\", \"code\": resp.status_code}\n",
    "        else:\n",
    "            return {\"error\": resp.status_code, \"message\": resp.text}\n",
    "    \n",
    "    def create_source(self, name: str, index_name: str, content_fields: list, title_field: str, url_field: str = None):\n",
    "        \"\"\"Create a knowledge source pointing to an existing search index.\"\"\"\n",
    "        # Build source_data_fields from content_fields and title_field\n",
    "        source_data_fields = [{\"name\": f} for f in content_fields]\n",
    "        if title_field:\n",
    "            source_data_fields.append({\"name\": title_field})\n",
    "        \n",
    "        body = {\n",
    "            \"name\": name,\n",
    "            \"kind\": \"searchIndex\",\n",
    "            \"description\": f\"Knowledge source for {index_name}\",\n",
    "            \"searchIndexParameters\": {\n",
    "                \"searchIndexName\": index_name,\n",
    "                \"semanticConfigurationName\": \"semantic-config\",\n",
    "                \"sourceDataFields\": source_data_fields,\n",
    "                \"searchFields\": []\n",
    "            }\n",
    "        }\n",
    "        resp = requests.put(f\"{self.search_endpoint}/knowledgesources/{name}?api-version={self.api_version}\",\n",
    "                           headers=self._headers(), json=body)\n",
    "        return self._parse_response(resp)\n",
    "    \n",
    "    def create_kb(self, name: str, sources: list, description: str, apim_url: str, apim_key: str, model: str):\n",
    "        \"\"\"Create a knowledge base that references one or more knowledge sources.\"\"\"\n",
    "        body = {\n",
    "            \"name\": name,\n",
    "            \"knowledgeSources\": [{\"name\": s} for s in sources],\n",
    "            \"description\": description,\n",
    "            \"models\": [\n",
    "                {\n",
    "                    \"kind\": \"azureOpenAI\",\n",
    "                    \"azureOpenAIParameters\": {\n",
    "                        \"resourceUri\": apim_url.replace('/openai', ''),\n",
    "                        \"deploymentId\": model,\n",
    "                        \"modelName\": model,\n",
    "                        \"apiKey\": apim_key\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"retrievalReasoningEffort\": {\"kind\": \"low\"}\n",
    "        }\n",
    "        resp = requests.put(f\"{self.search_endpoint}/knowledgebases/{name}?api-version={self.api_version}\",\n",
    "                           headers=self._headers(), json=body)\n",
    "        return self._parse_response(resp)\n",
    "    \n",
    "    def query(self, kb_name: str, query: str):\n",
    "        \"\"\"Query a knowledge base using the retrieve action.\"\"\"\n",
    "        body = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"type\": \"text\", \"text\": query}]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        resp = requests.post(f\"{self.search_endpoint}/knowledgebases/{kb_name}/retrieve?api-version={self.api_version}\",\n",
    "                            headers=self._headers(), json=body)\n",
    "        return self._parse_response(resp)\n",
    "    \n",
    "    def mcp_url(self, kb_name: str) -> str:\n",
    "        return f\"{self.search_endpoint}/knowledgebases/{kb_name}/mcp?api-version={self.api_version}\"\n",
    "\n",
    "\n",
    "def get_search_token():\n",
    "    return credential.get_token(\"https://search.azure.com/.default\").token\n",
    "\n",
    "iq = FoundryIQClient(SEARCH_ENDPOINT, get_search_token)\n",
    "print(\"‚úÖ Foundry IQ client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34921075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data source 'apollo-14-research-source' created!\n"
     ]
    }
   ],
   "source": [
    "# Create data source\n",
    "SOURCE_NAME = f\"{INDEX_NAME}-source\"\n",
    "result = iq.create_source(SOURCE_NAME, INDEX_NAME, [\"content\"], \"title\", None)\n",
    "if 'error' not in result:\n",
    "    print(f\"‚úÖ Data source '{SOURCE_NAME}' created!\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create knowledge base\n",
    "KB_NAME = f\"{INDEX_NAME}-kb\"\n",
    "result = iq.create_kb(KB_NAME, [SOURCE_NAME], f\"NASA Technical Reports: {SEARCH_TERM}\", APIM_URL, APIM_KEY, MODEL_NAME)\n",
    "\n",
    "if 'error' not in result:\n",
    "    print(f\"‚úÖ Knowledge base '{KB_NAME}' ready!\")\n",
    "    MCP_URL = iq.mcp_url(KB_NAME)\n",
    "    print(f\"   MCP Endpoint: {MCP_URL[:80]}...\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "987d0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Knowledge base working!\n",
      "   Response messages: 1\n",
      "   References: 5\n",
      "   First response: [{\"ref_id\":0,\"title\":\"Apollo 14 laser ranging retro-reflector experiment - Design certification review report\",\"content\":\"lc:t--. \\\"r. r 1\\nS,\\t DY-SICN VERIFICATIONr\\n3.\\t 1 I_KRR TESY PRO(-,.RAM\\n`,...\n"
     ]
    }
   ],
   "source": [
    "# Test knowledge base\n",
    "test_result = iq.query(KB_NAME, \"What scientific instruments did Apollo 14 deploy?\")\n",
    "if 'error' not in test_result:\n",
    "    # Check for response content\n",
    "    response = test_result.get('response', [])\n",
    "    references = test_result.get('references', [])\n",
    "    print(f\"‚úÖ Knowledge base working!\")\n",
    "    print(f\"   Response messages: {len(response)}\")\n",
    "    print(f\"   References: {len(references)}\")\n",
    "    if response:\n",
    "        for msg in response:\n",
    "            content = msg.get('content', [])\n",
    "            if content:\n",
    "                text = content[0].get('text', '')[:200]\n",
    "                print(f\"   First response: {text}...\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {test_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39def5c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#  Deep Research with Function Calling\n",
    "\n",
    "Now we run **o3-deep-research** using **function calling** instead of MCP.\n",
    "\n",
    "This approach:\n",
    "1. Uses Azure OpenAI Chat Completions API (which works today)\n",
    "2. Implements an **agentic loop** that continues until research is complete\n",
    "3. Provides `search` and `fetch` tools that query Foundry IQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87cf47",
   "metadata": {},
   "source": [
    "## Step 11: Define Research Tools\n",
    "\n",
    "These tools will be called by o3-deep-research during its research process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7cbd5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research tools defined\n",
      "   - search: Query Foundry IQ knowledge base\n",
      "   - fetch: Get full document content for citation\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "# Document cache for fetch operations\n",
    "_doc_cache: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "# =============================================================================\n",
    "# TOOL DEFINITIONS (OpenAI Function Calling Schema)\n",
    "# =============================================================================\n",
    "\n",
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search\",\n",
    "            \"description\": \"Search NASA Technical Reports for relevant documents. Returns summaries with IDs that can be fetched for full content.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Natural language search query\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"fetch\",\n",
    "            \"description\": \"Fetch complete document content by ID. Use after search to get full details for citation.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"document_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Document ID from search results\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"document_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# =============================================================================\n",
    "# TOOL IMPLEMENTATIONS (Query Foundry IQ)\n",
    "# =============================================================================\n",
    "\n",
    "def tool_search(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Search Foundry IQ knowledge base.\"\"\"\n",
    "    print(f\"   üîç search('{query[:50]}...')\")\n",
    "    \n",
    "    result = iq.query(KB_NAME, query)\n",
    "    \n",
    "    if 'error' in result:\n",
    "        return {\"error\": result['message'], \"results\": []}\n",
    "    \n",
    "    documents = []\n",
    "    \n",
    "    # Parse the response from Foundry IQ (2025-11-01-preview format)\n",
    "    response = result.get('response', [])\n",
    "    references = result.get('references', [])\n",
    "    \n",
    "    # Extract documents from the response content\n",
    "    for msg in response:\n",
    "        content = msg.get('content', [])\n",
    "        for item in content:\n",
    "            if item.get('type') == 'text':\n",
    "                try:\n",
    "                    # The text is a JSON array of documents\n",
    "                    docs_json = json.loads(item.get('text', '[]'))\n",
    "                    if isinstance(docs_json, list):\n",
    "                        for doc in docs_json[:10]:\n",
    "                            doc_id = str(doc.get('ref_id', hashlib.md5(str(doc).encode()).hexdigest()[:12]))\n",
    "                            parsed = {\n",
    "                                \"id\": doc_id,\n",
    "                                \"title\": doc.get('title', 'Untitled'),\n",
    "                                \"text\": doc.get('content', '')[:500] + \"...\",\n",
    "                                \"url\": f\"https://ntrs.nasa.gov/search\"\n",
    "                            }\n",
    "                            documents.append(parsed)\n",
    "                            # Cache full content for fetch\n",
    "                            _doc_cache[doc_id] = {\n",
    "                                \"id\": doc_id,\n",
    "                                \"title\": doc.get('title', 'Untitled'),\n",
    "                                \"text\": doc.get('content', ''),\n",
    "                                \"url\": parsed['url']\n",
    "                            }\n",
    "                except json.JSONDecodeError:\n",
    "                    # If not JSON, treat as plain text\n",
    "                    pass\n",
    "    \n",
    "    print(f\"      ‚Üí Found {len(documents)} documents\")\n",
    "    return {\"query\": query, \"total_results\": len(documents), \"results\": documents}\n",
    "\n",
    "\n",
    "def tool_fetch(document_id: str) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch cached document by ID.\"\"\"\n",
    "    print(f\"   üìÑ fetch('{document_id}')\")\n",
    "    \n",
    "    if document_id not in _doc_cache:\n",
    "        return {\"error\": f\"Document '{document_id}' not found. Use search first.\"}\n",
    "    \n",
    "    doc = _doc_cache[document_id]\n",
    "    print(f\"      ‚Üí Fetched: {doc['title'][:40]}...\")\n",
    "    return doc\n",
    "\n",
    "\n",
    "def execute_tool(name: str, arguments: Dict[str, Any]) -> str:\n",
    "    \"\"\"Execute a tool and return JSON result.\"\"\"\n",
    "    if name == \"search\":\n",
    "        result = tool_search(arguments.get(\"query\", \"\"))\n",
    "    elif name == \"fetch\":\n",
    "        result = tool_fetch(arguments.get(\"document_id\", \"\"))\n",
    "    else:\n",
    "        result = {\"error\": f\"Unknown tool: {name}\"}\n",
    "    \n",
    "    return json.dumps(result, indent=2)\n",
    "\n",
    "print(\"‚úÖ Research tools defined\")\n",
    "print(\"   - search: Query Foundry IQ knowledge base\")\n",
    "print(\"   - fetch: Get full document content for citation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489dae2",
   "metadata": {},
   "source": [
    "## Step 12: Initialize Azure OpenAI Clients\n",
    "\n",
    "All API calls go through **APIM gateway** for governance and rate limiting:\n",
    "- **Deep Research**: o3-deep-research via APIM (routed to Norway East backend)\n",
    "- **Final Synthesis**: gpt-4.1-mini via APIM (eastus2 hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f99cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# Initialize clients - all calls go through APIM gateway from Lab 1a\n",
    "# APIM routes o3-deep-research to Norway East backend automatically\n",
    "deep_research_client = AzureOpenAI(\n",
    "    azure_endpoint=APIM_URL.replace('/openai', ''),\n",
    "    api_key=APIM_KEY,\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "# Chat client for final report synthesis (gpt-4.1-mini via APIM)\n",
    "chat_client = AzureOpenAI(\n",
    "    azure_endpoint=APIM_URL.replace('/openai', ''),\n",
    "    api_key=APIM_KEY,\n",
    "    api_version=\"2024-10-21\",\n",
    "    timeout=120\n",
    ")\n",
    "\n",
    "print(f\"Azure OpenAI clients initialized (via APIM gateway)\")\n",
    "print(f\"   APIM Gateway:        {APIM_URL}\")\n",
    "print(f\"   Deep Research Model: {DEEP_RESEARCH_MODEL}\")\n",
    "print(f\"   Synthesis Model:     {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd48ac",
   "metadata": {},
   "source": [
    "## Step 13: Run Deep Research\n",
    "\n",
    "This runs an **agentic loop** where o3-deep-research:\n",
    "1. Analyzes the query and plans research steps\n",
    "2. Calls `search` to find relevant documents\n",
    "3. Calls `fetch` to get full content for promising results\n",
    "4. **gpt-4.1-mini** synthesizes findings into a comprehensive final report\n",
    "\n",
    "> üîí All API calls are routed through **APIM gateway** for governance and rate limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0e5f85c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Deep research function ready\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class ResearchResult:\n",
    "    \"\"\"Results from deep research.\"\"\"\n",
    "    query: str\n",
    "    iterations: int = 0\n",
    "    tool_calls: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    final_answer: str = \"\"\n",
    "    reasoning_tokens: int = 0\n",
    "    total_tokens: int = 0\n",
    "    duration_seconds: float = 0.0\n",
    "    error: Optional[str] = None\n",
    "\n",
    "\n",
    "def run_deep_research(query: str) -> ResearchResult:\n",
    "    \"\"\"\n",
    "    Run deep research using agentic loop with function calling.\n",
    "    \"\"\"\n",
    "    result = ResearchResult(query=query)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # System prompt for research behavior\n",
    "    system_prompt = f\"\"\"You are a deep research assistant with access to NASA Technical Reports about {SEARCH_TERM}.\n",
    "\n",
    "Your task is to thoroughly research the user's query by:\n",
    "1. Use the 'search' tool to find relevant documents in the knowledge base\n",
    "2. Use the 'fetch' tool to get full content of the most relevant documents\n",
    "3. Analyze and synthesize the information\n",
    "4. Provide a comprehensive, well-cited answer\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "- Search multiple times with different queries to get comprehensive coverage\n",
    "- Fetch all documents that seem relevant before writing your final answer\n",
    "- Include specific facts, dates, figures, and technical details from the documents\n",
    "- Cite your sources using document IDs (e.g., [doc-abc123])\n",
    "- Structure your final answer with clear sections and headers\n",
    "- Be thorough - this is deep research, not a quick summary\n",
    "\n",
    "When you have gathered enough information, provide your final research report.\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üî¨ DEEP RESEARCH STARTED\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Query: {query[:80]}...\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        for iteration in range(MAX_RESEARCH_ITERATIONS):\n",
    "            print(f\"\\nüìç Iteration {iteration + 1}/{MAX_RESEARCH_ITERATIONS}\")\n",
    "            \n",
    "            # Call the model\n",
    "            response = deep_research_client.chat.completions.create(\n",
    "                model=DEEP_RESEARCH_MODEL,\n",
    "                messages=messages,\n",
    "                tools=TOOLS\n",
    "            )\n",
    "            \n",
    "            message = response.choices[0].message\n",
    "            result.total_tokens += response.usage.total_tokens if response.usage else 0\n",
    "            \n",
    "            # Check for reasoning tokens (o3 specific)\n",
    "            if response.usage and hasattr(response.usage, 'completion_tokens_details'):\n",
    "                details = response.usage.completion_tokens_details\n",
    "                if details and hasattr(details, 'reasoning_tokens'):\n",
    "                    result.reasoning_tokens += details.reasoning_tokens or 0\n",
    "            \n",
    "            # If no tool calls, we have gathered info - synthesize with gpt-4.1-mini\n",
    "            if not message.tool_calls:\n",
    "                print(\"\\n‚úÖ Research complete, synthesizing final report with gpt-4.1-mini...\")\n",
    "                \n",
    "                # Gather all research context for synthesis\n",
    "                research_context = message.content or \"\"\n",
    "                \n",
    "                # Create synthesis prompt with all gathered information\n",
    "                synthesis_messages = [\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You are an expert research report writer. \n",
    "Based on the research conducted by the deep research model, write a comprehensive, well-structured final report.\n",
    "\n",
    "GUIDELINES:\n",
    "- Structure the report with clear headers and sections\n",
    "- Include specific facts, dates, figures, and technical details\n",
    "- Cite sources using document IDs where available (e.g., [doc-abc123])\n",
    "- Be thorough and comprehensive\n",
    "- Use professional academic writing style\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"Based on this research about {SEARCH_TERM}, write a comprehensive final report:\n",
    "\n",
    "ORIGINAL QUERY:\n",
    "{query}\n",
    "\n",
    "RESEARCH FINDINGS:\n",
    "{research_context}\n",
    "\n",
    "Please synthesize this into a well-organized, comprehensive research report.\"\"\"}\n",
    "                ]\n",
    "                \n",
    "                # Use gpt-4.1-mini for final synthesis\n",
    "                synthesis_response = chat_client.chat.completions.create(\n",
    "                    model=MODEL_NAME,\n",
    "                    messages=synthesis_messages\n",
    "                )\n",
    "                \n",
    "                result.final_answer = synthesis_response.choices[0].message.content or \"\"\n",
    "                if synthesis_response.usage:\n",
    "                    result.total_tokens += synthesis_response.usage.total_tokens\n",
    "                result.iterations = iteration + 1\n",
    "                break\n",
    "            \n",
    "            # Process tool calls\n",
    "            messages.append(message)\n",
    "            \n",
    "            for tool_call in message.tool_calls[:5]:  # Limit per iteration\n",
    "                func_name = tool_call.function.name\n",
    "                \n",
    "                # Parse arguments with error handling for malformed JSON\n",
    "                try:\n",
    "                    func_args = json.loads(tool_call.function.arguments)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Try to fix common JSON issues (trailing commas)\n",
    "                    import re\n",
    "                    fixed_args = re.sub(r',\\s*}', '}', tool_call.function.arguments)\n",
    "                    fixed_args = re.sub(r',\\s*]', ']', fixed_args)\n",
    "                    try:\n",
    "                        func_args = json.loads(fixed_args)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"   ‚ö†Ô∏è Skipping malformed tool call: {tool_call.function.arguments[:50]}...\")\n",
    "                        continue\n",
    "                \n",
    "                # Execute tool\n",
    "                tool_result = execute_tool(func_name, func_args)\n",
    "                \n",
    "                # Record tool call\n",
    "                result.tool_calls.append({\n",
    "                    \"iteration\": iteration + 1,\n",
    "                    \"tool\": func_name,\n",
    "                    \"arguments\": func_args\n",
    "                })\n",
    "                \n",
    "                # Add tool response to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": tool_result\n",
    "                })\n",
    "            \n",
    "            # Check if max iterations reached\n",
    "            if iteration == MAX_RESEARCH_ITERATIONS - 1:\n",
    "                print(\"\\n‚ö†Ô∏è Max iterations reached, synthesizing final report with gpt-4.1-mini...\")\n",
    "                \n",
    "                # Gather all tool call results for synthesis\n",
    "                # Handle both dict messages and ChatCompletionMessage objects\n",
    "                gathered_info = []\n",
    "                for msg in messages:\n",
    "                    if isinstance(msg, dict):\n",
    "                        if msg.get(\"role\") == \"tool\":\n",
    "                            gathered_info.append(msg.get(\"content\", \"\"))\n",
    "                    # Skip ChatCompletionMessage objects (they don't have tool results)\n",
    "                \n",
    "                # Create synthesis prompt\n",
    "                synthesis_messages = [\n",
    "                    {\"role\": \"system\", \"content\": f\"\"\"You are an expert research report writer.\n",
    "Based on the research data gathered about {SEARCH_TERM}, write a comprehensive, well-structured final report.\n",
    "\n",
    "GUIDELINES:\n",
    "- Structure the report with clear headers and sections\n",
    "- Include specific facts, dates, figures, and technical details\n",
    "- Cite sources using document IDs where available (e.g., [doc-abc123])\n",
    "- Be thorough and comprehensive\n",
    "- Use professional academic writing style\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"Based on this research about {SEARCH_TERM}, write a comprehensive final report:\n",
    "\n",
    "ORIGINAL QUERY:\n",
    "{query}\n",
    "\n",
    "GATHERED RESEARCH DATA:\n",
    "{chr(10).join(gathered_info[:5])}\n",
    "\n",
    "Please synthesize this into a well-organized, comprehensive research report.\"\"\"}\n",
    "                ]\n",
    "                \n",
    "                # Use gpt-4.1-mini for final synthesis\n",
    "                final_response = chat_client.chat.completions.create(\n",
    "                    model=MODEL_NAME,\n",
    "                    messages=synthesis_messages\n",
    "                )\n",
    "                result.final_answer = final_response.choices[0].message.content or \"\"\n",
    "                result.iterations = iteration + 1\n",
    "                if final_response.usage:\n",
    "                    result.total_tokens += final_response.usage.total_tokens\n",
    "        \n",
    "    except Exception as e:\n",
    "        result.error = str(e)\n",
    "        print(f\"\\n‚ùå Error: {e}\")\n",
    "    \n",
    "    result.duration_seconds = round(time.time() - start_time, 2)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üî¨ DEEP RESEARCH COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"   Iterations:       {result.iterations}\")\n",
    "    print(f\"   Tool calls:       {len(result.tool_calls)}\")\n",
    "    print(f\"   Total tokens:     {result.total_tokens:,}\")\n",
    "    print(f\"   Reasoning tokens: {result.reasoning_tokens:,}\")\n",
    "    print(f\"   Duration:         {result.duration_seconds}s\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"‚úÖ Deep research function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4590e374",
   "metadata": {},
   "source": [
    "## Step 14: Execute Deep Research Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f9f1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî¨ DEEP RESEARCH STARTED\n",
      "============================================================\n",
      "Query: Research Apollo 14 comprehensively. \n",
      "I need to understand:\n",
      "1. What was special a...\n",
      "\n",
      "\n",
      "üìç Iteration 1/25\n",
      "   üîç search('Apollo 14 Preliminary Science Report NASA SP-272...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 2/25\n",
      "   üîç search('\"Apollo 14 Preliminary Science Report\"...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 3/25\n",
      "   üîç search('Apollo 14 ALSEP...')\n",
      "      ‚Üí Found 4 documents\n",
      "\n",
      "üìç Iteration 4/25\n",
      "   üîç search('Apollo 14 ALSEP experiments list passive seismic c...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 5/25\n",
      "   üîç search('Apollo 14 mission summary results science...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 6/25\n",
      "   üîç search('1971027929...')\n",
      "      ‚Üí Found 7 documents\n",
      "\n",
      "üìç Iteration 7/25\n",
      "   üîç search('Apollo 14 NASA SP science report 1971...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 8/25\n",
      "   üîç search('\"Apollo 14\" and \"ALSEP\" and experiment...')\n",
      "      ‚Üí Found 4 documents\n",
      "\n",
      "üìç Iteration 9/25\n",
      "   üîç search('Apollo 14 lunar samples geology findings...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 10/25\n",
      "   üìÑ fetch('1971027929')\n",
      "\n",
      "üìç Iteration 11/25\n",
      "   üìÑ fetch('1971027929-002')\n",
      "\n",
      "üìç Iteration 12/25\n",
      "   üîç search('\"Apollo 14 mission, 5 day report\" 1971 NASA...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 13/25\n",
      "   üìÑ fetch('1971027929-002')\n",
      "\n",
      "üìç Iteration 14/25\n",
      "   üîç search('Apollo 14 mission evaluation report...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 15/25\n",
      "   üîç search('\"Apollo 14 Preliminary Science Report\" NTRS docume...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 16/25\n",
      "   üîç search('Charged Particle Lunar Apollo 14 2.5 degrees horiz...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 17/25\n",
      "   üîç search('Apollo 14 docking latch problem mission special fi...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 18/25\n",
      "   üîç search('Apollo 14 lunar samples findings basalt breccia hi...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 19/25\n",
      "   üîç search('Apollo 14 breccia Imbrium 4.1 billion...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 20/25\n",
      "   üîç search('Apollo 14 improvements after Apollo 13 differences...')\n",
      "      ‚Üí Found 4 documents\n",
      "\n",
      "üìç Iteration 21/25\n",
      "   üîç search('\"Apollo 14 Science at Fra Mauro\" EP-91...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 22/25\n",
      "   üîç search('\"Apollo 14 Science at Fra Mauro\" Apollo 14 finding...')\n",
      "      ‚Üí Found 7 documents\n",
      "\n",
      "üìç Iteration 23/25\n",
      "   üîç search('\"NASA SP-272\" Apollo 14...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "üìç Iteration 24/25\n",
      "   üîç search('\"Apollo 14\" and \"Preliminary Science Report\"...')\n",
      "      ‚Üí Found 6 documents\n",
      "\n",
      "üìç Iteration 25/25\n",
      "   üîç search('\"Apollo 14\" \"lunar samples\" analysis...')\n",
      "      ‚Üí Found 5 documents\n",
      "\n",
      "‚ö†Ô∏è Max iterations reached, synthesizing final report with gpt-4.1-mini...\n",
      "\n",
      "============================================================\n",
      "üî¨ DEEP RESEARCH COMPLETE\n",
      "============================================================\n",
      "   Iterations:       25\n",
      "   Tool calls:       25\n",
      "   Total tokens:     428,601\n",
      "   Reasoning tokens: 7,552\n",
      "   Duration:         170.33s\n"
     ]
    }
   ],
   "source": [
    "# Clear document cache for fresh research\n",
    "_doc_cache.clear()\n",
    "\n",
    "# Define research query\n",
    "research_query = f\"\"\"Research {SEARCH_TERM} comprehensively. \n",
    "I need to understand:\n",
    "1. What was special about this mission?\n",
    "2. What scientific instruments were deployed?\n",
    "3. What were the key findings from the lunar samples?\n",
    "4. Who was the commander and what made him notable?\n",
    "\n",
    "Provide a detailed research report with specific facts, dates, and citations.\"\"\"\n",
    "\n",
    "# Run deep research\n",
    "research_result = run_deep_research(research_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43f7b2",
   "metadata": {},
   "source": [
    "## Step 15: Display Research Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4219122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"font-family: system-ui; padding: 20px; background: linear-gradient(135deg, #1a1a2e, #16213e); \n",
       "                border-radius: 12px; margin: 10px 0;\">\n",
       "        <h2 style=\"color: #4da6ff; margin: 0 0 15px 0;\">üî¨ Deep Research Results</h2>\n",
       "        <div style=\"display: flex; gap: 20px; flex-wrap: wrap;\">\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #4da6ff; font-weight: bold;\">25</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Iterations</div>\n",
       "            </div>\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #28a745; font-weight: bold;\">25</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Tool Calls</div>\n",
       "            </div>\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #ffc107; font-weight: bold;\">428,601</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Total Tokens</div>\n",
       "            </div>\n",
       "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
       "                <div style=\"font-size: 24px; color: #e94560; font-weight: bold;\">170.33s</div>\n",
       "                <div style=\"color: #888; font-size: 12px;\">Duration</div>\n",
       "            </div>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n",
       "## üìÑ Research Report\n",
       "\n",
       "# Apollo 14 Mission: Final Research Report\n",
       "\n",
       "---\n",
       "\n",
       "## Executive Summary\n",
       "\n",
       "Apollo 14, launched on January 31, 1971, was the eighth crewed mission in NASA‚Äôs Apollo program and the third to land humans on the Moon. This mission was notable for its rigorous scientific objectives, the deployment of a comprehensive suite of surface experiments, and the significant achievements of its commander, Alan B. Shepard Jr. The mission successfully collected lunar samples, contributed important seismic and environmental data about the Moon, and demonstrated improved surface landing precision. This report presents a detailed analysis of the mission‚Äôs special features, scientific instruments, key findings from lunar samples, and the background of the crew commander, supported by citations from NASA‚Äôs Apollo 14 Preliminary Science Reports and related documents [doc-1971027929-002; doc-1971027929-006; doc-1971027929-007; doc-1971027929-004; doc-1971027929-008].\n",
       "\n",
       "---\n",
       "\n",
       "## 1. Introduction and Mission Overview\n",
       "\n",
       "Apollo 14 (AS-509) was launched from Cape Kennedy, Florida, on January 31, 1971, with the primary goal of conducting high-quality scientific investigation of the lunar surface and returning valuable samples to Earth [doc-1971027929-002]. The mission lasted approximately five days, encompassing trans-lunar injection, powered descent to the lunar surface, two extravehicular activities (EVAs), and a safe return to Earth.\n",
       "\n",
       "Distinct from previous Apollo missions, Apollo 14 sought to improve precision in lunar landing through demonstration of a point-landing capability and expanded scientific exploration beyond earlier missions‚Äô scope. The mission focused on exploration of the Fra Mauro highlands, a geologically significant area believed to contain ejecta from the Imbrium basin, thus providing insight into large lunar impact processes and crustal evolution [doc-1971027929-002].\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Special Characteristics of Apollo 14 Mission\n",
       "\n",
       "### 2.1 Demonstrated Precision Landing and Enhanced Surface Mobility\n",
       "\n",
       "- The mission successfully demonstrated improved targeting accuracy for lunar module landing within a few meters of the designated site coordinates [doc-1971027929-002].\n",
       "\n",
       "- The astronauts‚Äô traverses covered expanded surface areas, allowing comprehensive geological sampling and deployment of experiments.\n",
       "\n",
       "### 2.2 Restoration of Activity after Apollo 13 Incident\n",
       "\n",
       "- Apollo 14 was the first mission flown following the Apollo 13 failure; it was pivotal in restoring confidence in NASA‚Äôs lunar exploration capabilities.\n",
       "\n",
       "### 2.3 Commander Alan B. Shepard Jr.‚Äôs Return to Space\n",
       "\n",
       "- Alan B. Shepard Jr., NASA‚Äôs first American astronaut in space (Mercury-Redstone 3, 1961), commanded Apollo 14, marking his return to space after a 37-year gap and overcoming M√©ni√®re‚Äôs disease that had grounded him for years [doc-1971027929-004].\n",
       "\n",
       "- Shepard‚Äôs lunar activities included manually piloting the lunar module during descent, operating scientific equipment, and demonstrating physical tasks such as golf shots on the lunar surface.\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Scientific Instruments and Lunar Surface Experiments\n",
       "\n",
       "Apollo 14 carried and deployed a comprehensive **Apollo Lunar Surface Experiments Package (ALSEP)**, designed to collect long-term scientific data from the Moon.\n",
       "\n",
       "### 3.1 ALSEP Instruments Deployed\n",
       "\n",
       "- **Passive Seismic Experiment**: Measured moonquakes and seismic activity to characterize the lunar subsurface structure. All sensors operated properly except the long-period vertical component seismometer, which had an unexpected longer natural period [doc-1971027929-007].\n",
       "\n",
       "- **Charged Particle Lunar Environment Experiment**: Positioned due east of the lunar module, leveled within 2.5¬∞ of horizontal, it recorded charged particle fluxes, with high voltages and temperatures stable within nominal parameters [doc-1971027929-008].\n",
       "\n",
       "- **Heat Flow Experiment**: Designed to determine thermal gradients and conductivity in the lunar regolith; initial results indicated complexities related to soil compaction and contact with instruments, relevant for understanding lunar thermal properties [doc-1971027929-002].\n",
       "\n",
       "- **Laser Ranging Retro-Reflector**: Similar to devices on Apollo 11, used for precisely measuring the Earth-Moon distance via reflected laser pulses [doc-1971027929-008].\n",
       "\n",
       "- **Lunar Module Surface Equipment**: Included television cameras (color and black & white with zoom lenses), an S-band steerable antenna for communications, and radiation dosimeters to monitor crew exposure [doc-1971027929-004; doc-1971027929-025].\n",
       "\n",
       "### 3.2 Additional Scientific Measurements\n",
       "\n",
       "- Electric field measurements on the lunar surface recorded field strengths up to 8000 volts/meter, comparable but higher than the Apollo 12 lightning episode (estimated 7500 volts/meter) [doc-1971027929-006].\n",
       "\n",
       "- Radiometer and radio noise experiments assessed the Saturn vehicle exhaust plume and the lunar environment‚Äôs electromagnetic characteristics [doc-1971027929-006].\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Key Findings from Lunar Samples\n",
       "\n",
       "### 4.1 Geological Context\n",
       "\n",
       "- Apollo 14 targeted the Fra Mauro formation, recognized for containing impact ejecta from the ancient Imbrium basin, critical to understanding the Moon‚Äôs geological history and stratigraphy [doc-1971027929-002].\n",
       "\n",
       "### 4.2 Sample Collection and Evaluation\n",
       "\n",
       "- The crews collected rock and soil samples with an array of compositions, including brecciated impact rocks and regolith materials.\n",
       "\n",
       "- Preliminary analyses revealed properties related to the thermal history and mechanical compaction of samples, with directional solidification patterns investigated postflight to simulate lunar formation conditions [doc-1971027929-005].\n",
       "\n",
       "- Apollo 14 samples contributed to advancing knowledge of lunar thermal conductivity, with experiments noting issues related to contact between molten samples and container walls during laboratory simulations, emphasizing the need for precise thermal modeling [doc-1971027929-005].\n",
       "\n",
       "### 4.3 Implications for Lunar Science\n",
       "\n",
       "- Seismic data and sample characterization supported theories of the Moon‚Äôs layered structure and impact history.\n",
       "\n",
       "- Sample properties enhanced understanding of pore and bubble distribution in lunar material, affecting interpretations of lunar volcanism and regolith evolution [doc-1971027929-005].\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Commander Alan B. Shepard Jr.: Profile and Notability\n",
       "\n",
       "### 5.1 Background\n",
       "\n",
       "- Alan Bartlett Shepard Jr., one of NASA's original Mercury Seven astronauts, became the first American in space on May 5, 1961, aboard Mercury-Redstone 3 (Freedom 7).\n",
       "\n",
       "### 5.2 Notable Achievements\n",
       "\n",
       "- After being grounded for M√©ni√®re‚Äôs syndrome, Shepard underwent successful medical treatment, enabling his return to flight status.\n",
       "\n",
       "- He commanded Apollo 14, personally flying the lunar module during descent and conducting two lunar EVAs.\n",
       "\n",
       "- Shepard famously hit golf balls on the lunar surface using a makeshift club, demonstrating human capabilities in reduced gravity [doc-1971027929-004].\n",
       "\n",
       "- His leadership on Apollo 14 was essential for mission success, especially in overcoming technical and physical challenges post-Apollo 13.\n",
       "\n",
       "---\n",
       "\n",
       "## 6. Conclusion\n",
       "\n",
       "Apollo 14 was a landmark mission that restored momentum in lunar exploration by combining precise landing capabilities, robust scientific experimentation through ALSEP and sample collection, and the experienced command of Alan Shepard. The mission‚Äôs multiple scientific instruments yielded valuable data on lunar seismicity, environment, and surface properties. Furthermore, the lunar samples acquired contributed substantially to understanding the Moon‚Äôs geological history and physical characteristics. Apollo 14‚Äôs success cemented it as an important chapter in humanity‚Äôs continuing exploration of the Moon.\n",
       "\n",
       "---\n",
       "\n",
       "## 7. References\n",
       "\n",
       "- NASA Manned Spacecraft Center, *Apollo 14 Mission 5-Day Report*, February 1971, Document ID: 1971027929-002.\n",
       "\n",
       "- NASA Manned Spacecraft Center, *Apollo 14 Mission Scientific Experiments and Data*, February 1971, Document IDs: 1971027929-004, 1971027929-006, 1971027929-007, 1971027929-008, 1971027929-025.\n",
       "\n",
       "- Arthur D. Little, Inc., *Apollo 14 Composite Casting Demonstration and Sample Evaluation*, associated with Apollo 14 lunar samples, 1971, Document IDs: 1971027929-005.\n",
       "\n",
       "---\n",
       "\n",
       "*This report synthesizes official NASA documentation and technical reports pertaining to the Apollo 14 mission to provide a detailed and scholarly overview of its objectives, accomplishments, and scientific contributions.*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the research report\n",
    "if research_result.error:\n",
    "    display(HTML(f'<div style=\"background:#ffdddd;padding:15px;border-radius:8px;\">'\n",
    "                 f'<h3>‚ùå Research Error</h3><p>{research_result.error}</p></div>'))\n",
    "else:\n",
    "    # Summary card\n",
    "    html = f'''\n",
    "    <div style=\"font-family: system-ui; padding: 20px; background: linear-gradient(135deg, #1a1a2e, #16213e); \n",
    "                border-radius: 12px; margin: 10px 0;\">\n",
    "        <h2 style=\"color: #4da6ff; margin: 0 0 15px 0;\">üî¨ Deep Research Results</h2>\n",
    "        <div style=\"display: flex; gap: 20px; flex-wrap: wrap;\">\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #4da6ff; font-weight: bold;\">{research_result.iterations}</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Iterations</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #28a745; font-weight: bold;\">{len(research_result.tool_calls)}</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Tool Calls</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #ffc107; font-weight: bold;\">{research_result.total_tokens:,}</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Total Tokens</div>\n",
    "            </div>\n",
    "            <div style=\"background: rgba(15,52,96,0.3); padding: 12px 20px; border-radius: 8px; text-align: center;\">\n",
    "                <div style=\"font-size: 24px; color: #e94560; font-weight: bold;\">{research_result.duration_seconds}s</div>\n",
    "                <div style=\"color: #888; font-size: 12px;\">Duration</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    '''\n",
    "    display(HTML(html))\n",
    "    \n",
    "    # Research report\n",
    "    display(Markdown(\"---\\n## üìÑ Research Report\\n\\n\" + research_result.final_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d718151",
   "metadata": {},
   "source": [
    "## Step 16: Analyze Tool Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9f9305b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üîß Tool Call Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search calls: 22\n",
      "Fetch calls:  3\n",
      "\n",
      "Search queries:\n",
      "  1. Apollo 14 Preliminary Science Report NASA SP-272...\n",
      "  2. \"Apollo 14 Preliminary Science Report\"...\n",
      "  3. Apollo 14 ALSEP...\n",
      "  4. Apollo 14 ALSEP experiments list passive seismic charged particle heat...\n",
      "  5. Apollo 14 mission summary results science...\n",
      "  6. 1971027929...\n",
      "  7. Apollo 14 NASA SP science report 1971...\n",
      "  8. \"Apollo 14\" and \"ALSEP\" and experiment...\n",
      "  9. Apollo 14 lunar samples geology findings...\n",
      "  10. \"Apollo 14 mission, 5 day report\" 1971 NASA...\n",
      "  11. Apollo 14 mission evaluation report...\n",
      "  12. \"Apollo 14 Preliminary Science Report\" NTRS document...\n",
      "  13. Charged Particle Lunar Apollo 14 2.5 degrees horizontal system was che...\n",
      "  14. Apollo 14 docking latch problem mission special first...\n",
      "  15. Apollo 14 lunar samples findings basalt breccia highlands Fra Mauro Im...\n",
      "  16. Apollo 14 breccia Imbrium 4.1 billion...\n",
      "  17. Apollo 14 improvements after Apollo 13 differences...\n",
      "  18. \"Apollo 14 Science at Fra Mauro\" EP-91...\n",
      "  19. \"Apollo 14 Science at Fra Mauro\" Apollo 14 findings...\n",
      "  20. \"NASA SP-272\" Apollo 14...\n",
      "  21. \"Apollo 14\" and \"Preliminary Science Report\"...\n",
      "  22. \"Apollo 14\" \"lunar samples\" analysis...\n",
      "\n",
      "Documents fetched: 3\n"
     ]
    }
   ],
   "source": [
    "# Show tool call breakdown\n",
    "if research_result.tool_calls:\n",
    "    display(Markdown(\"### üîß Tool Call Summary\"))\n",
    "    \n",
    "    search_calls = [t for t in research_result.tool_calls if t['tool'] == 'search']\n",
    "    fetch_calls = [t for t in research_result.tool_calls if t['tool'] == 'fetch']\n",
    "    \n",
    "    print(f\"Search calls: {len(search_calls)}\")\n",
    "    print(f\"Fetch calls:  {len(fetch_calls)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Search queries:\")\n",
    "    for i, call in enumerate(search_calls, 1):\n",
    "        query = call['arguments'].get('query', 'N/A')\n",
    "        print(f\"  {i}. {query[:70]}...\")\n",
    "    \n",
    "    print(f\"\\nDocuments fetched: {len(fetch_calls)}\")\n",
    "else:\n",
    "    print(\"No tool calls recorded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4432fd0a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've completed the **Deep Research** lab using:\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **o3-deep-research** | Advanced reasoning model (deployed in Lab 1a, accessed via APIM) |\n",
    "| **gpt-4.1-mini** | Final report synthesis (deployed in Lab 1a, accessed via APIM) |\n",
    "| **APIM Gateway** | All API calls routed through gateway for governance |\n",
    "| **Foundry IQ** | Knowledge base for NASA Technical Reports |\n",
    "| **Agentic Loop** | Iterative search, fetch, synthesize pattern |\n",
    "\n",
    "### Architecture\n",
    "\n",
    "This lab demonstrates the **Landing Zone pattern**:\n",
    "- Models (including o3-deep-research) are deployed centrally in **Lab 1a**\n",
    "- APIM automatically routes o3-deep-research requests to the Norway East backend\n",
    "- This lab only deploys **Azure AI Search** for Foundry IQ knowledge bases\n",
    "- All model access goes through APIM for governance, rate limiting, and observability\n",
    "\n",
    "### Configuration\n",
    "\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| MAX_RESEARCH_ITERATIONS | 25 |\n",
    "| Deep Research Model | o3-deep-research (via APIM) |\n",
    "| Synthesis Model | gpt-4.1-mini (via APIM) |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Try different `SEARCH_TERM` values (\"Mars\", \"Voyager\", \"Space Shuttle\")\n",
    "- Adjust `MAX_RESEARCH_ITERATIONS` for more/less thorough research\n",
    "- Add more tools (web search, code execution)\n",
    "- Monitor usage via APIM analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf3ade",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa0d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete resources\n",
    "# !az group delete -n \"{RG}\" --yes --no-wait\n",
    "# print(\"‚úÖ Cleanup initiated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
