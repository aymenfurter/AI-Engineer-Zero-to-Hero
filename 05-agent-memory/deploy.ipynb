{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e72d468",
   "metadata": {},
   "source": [
    "# Lab 5: Agent Memory \n",
    "\n",
    "Build agents with **long-term memory** using Azure AI Foundry's Memory API.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "| Scenario | Description |\n",
    "|----------|-------------|\n",
    "| **1. Memory Store** | Create stores with local models |\n",
    "| **2. Store Memories** | Extract memories from conversations |\n",
    "| **3. Scope Isolation** | Keep user data separate |\n",
    "| **4. Agent + Memory** | Agent with `memory_search` tool |\n",
    "| **5. Cross-Session** | Memory persists across sessions |\n",
    "\n",
    "## Theme: Space Exploration Expert üöÄ\n",
    "\n",
    "This lab uses a **space exploration** theme - the agent remembers users' favorite planets, space interests, and exploration preferences.\n",
    "\n",
    "\n",
    "## Prerequisites- `.env` file with `APIM_URL`, `APIM_KEY`, `MODEL_NAME`\n",
    "\n",
    "- Complete **Lab 1A** (Landing Zone) - provides APIM gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e8196",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc3f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas requests azure-ai-projects==2.0.0b2 azure-identity openai -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e240a6",
   "metadata": {},
   "source": [
    "## Step 2: Load Landing Zone Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, json\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load .env file\n",
    "env_file = Path('/workspaces/getting-started-with-foundry/.env')\n",
    "if env_file.exists():\n",
    "    for line in env_file.read_text().splitlines():\n",
    "        if line.strip() and not line.startswith('#') and '=' in line:\n",
    "            key, value = line.split('=', 1)\n",
    "            os.environ[key] = value\n",
    "\n",
    "# Landing zone config\n",
    "APIM_URL = os.environ.get('APIM_URL', '')\n",
    "APIM_KEY = os.environ.get('APIM_KEY', '')\n",
    "GATEWAY_MODEL = os.environ.get('MODEL_NAME', 'gpt-4.1-mini')\n",
    "\n",
    "print(f\"‚úÖ APIM URL: {APIM_URL[:50]}...\" if APIM_URL else \"‚ùå APIM_URL not set\")\n",
    "print(f\"‚úÖ APIM Key: {APIM_KEY[:8]}...\" if APIM_KEY else \"‚ùå APIM_KEY not set\")\n",
    "print(f\"‚úÖ Gateway Model: {GATEWAY_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e5153",
   "metadata": {},
   "source": [
    "## Step 3: Set Spoke Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ea040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spoke configuration\n",
    "RG = \"foundry-memory-spoke\"\n",
    "LOCATION = \"eastus2\"\n",
    "LOCAL_CHAT_MODEL = \"gpt-4.1-mini\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "MEMORY_STORE_NAME = \"space-expert-memory\"\n",
    "\n",
    "PRINCIPAL_ID = subprocess.run(\n",
    "    'az ad signed-in-user show --query id -o tsv',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout.strip()\n",
    "\n",
    "display(Markdown(f'''\n",
    "| Setting | Value |\n",
    "|---------|-------|\n",
    "| Resource Group | `{RG}` |\n",
    "| Local Chat | `{LOCAL_CHAT_MODEL}` |\n",
    "| Embedding | `{EMBEDDING_MODEL}` |\n",
    "| Memory Store | `{MEMORY_STORE_NAME}` |\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ac27f",
   "metadata": {},
   "source": [
    "## Step 4: Create Resource Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4c1e1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\n",
      "----------  --------------------\n",
      "eastus2     foundry-memory-spoke\n"
     ]
    }
   ],
   "source": [
    "!az group create -n \"{RG}\" -l \"{LOCATION}\" -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb797b7",
   "metadata": {},
   "source": [
    "## Step 4: Deploy Spoke Infrastructure\n",
    "\n",
    "Deploys local models (for Memory API) + APIM connection. ‚è±Ô∏è ~4-5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "!az deployment group create -g \"{RG}\" --template-file spoke.bicep \\\n",
    "    -p deployerPrincipalId=\"{PRINCIPAL_ID}\" \\\n",
    "    -p apimUrl=\"{APIM_URL}\" \\\n",
    "    -p gatewayModelName=\"{GATEWAY_MODEL}\" \\\n",
    "    -p localChatModel=\"{LOCAL_CHAT_MODEL}\" \\\n",
    "    -p embeddingModelName=\"{EMBEDDING_MODEL}\" \\\n",
    "    -p apimSubscriptionKey=\"{APIM_KEY}\" \\\n",
    "    -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c1edf",
   "metadata": {},
   "source": [
    "## Step 6: Get Deployment Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = json.loads(subprocess.run(\n",
    "    f'az deployment group show -g \"{RG}\" -n spoke --query properties.outputs -o json',\n",
    "    shell=True, capture_output=True, text=True\n",
    ").stdout)\n",
    "\n",
    "ACCOUNT_NAME = outputs['accountName']['value']\n",
    "PROJECT_NAME = outputs['projectName']['value']\n",
    "PROJECT_ENDPOINT = outputs['projectEndpoint']['value']\n",
    "LOCAL_CHAT = outputs['localChatModel']['value']\n",
    "EMBEDDING = outputs['embeddingModelName']['value']\n",
    "\n",
    "print(f\"‚úÖ Account: {ACCOUNT_NAME}\")\n",
    "print(f\"‚úÖ Project: {PROJECT_NAME}\")\n",
    "print(f\"‚úÖ Local Chat: {LOCAL_CHAT}\")\n",
    "print(f\"‚úÖ Embedding: {EMBEDDING}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24da3dd9",
   "metadata": {},
   "source": [
    "## Step 7: Wait for RBAC Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7543824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ready\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i in range(60, 0, -10):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"‚è≥ RBAC propagation... {i}s\")\n",
    "    time.sleep(10)\n",
    "clear_output(wait=True)\n",
    "print(\"‚úÖ Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921a2c0",
   "metadata": {},
   "source": [
    "## Step 8a: Setup Project Client\n",
    "\n",
    "Use the SDK for clean Responses API access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68723d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "project_client = AIProjectClient(endpoint=PROJECT_ENDPOINT, credential=credential)\n",
    "openai_client = project_client.get_openai_client()\n",
    "\n",
    "print(f\"‚úÖ Project client ready: {PROJECT_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a980361d",
   "metadata": {},
   "source": [
    "## Step 8b: Setup Memory Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b8cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory client ready\n"
     ]
    }
   ],
   "source": [
    "from memory_helpers import MemoryClient, build_conversation\n",
    "from display_helpers import show_store_created, show_memories, show_search_results, show_agent_created, show_conversation, show_error\n",
    "\n",
    "memory = MemoryClient(ACCOUNT_NAME, PROJECT_NAME)\n",
    "print(f\"‚úÖ Memory client ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043cff62",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 1: Create Memory Store\n",
    "\n",
    "The memory store uses **local models** for internal processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10cff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Memory Store Created"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c4b4e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_c4b4e_level0_col0\" class=\"col_heading level0 col0\" >Property</th>\n",
       "      <th id=\"T_c4b4e_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_c4b4e_row0_col0\" class=\"data row0 col0\" >Name</td>\n",
       "      <td id=\"T_c4b4e_row0_col1\" class=\"data row0 col1\" >space-expert-memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c4b4e_row1_col0\" class=\"data row1 col0\" >Chat Model</td>\n",
       "      <td id=\"T_c4b4e_row1_col1\" class=\"data row1 col1\" >gpt-4.1-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c4b4e_row2_col0\" class=\"data row2 col0\" >Embedding Model</td>\n",
       "      <td id=\"T_c4b4e_row2_col1\" class=\"data row2 col1\" >text-embedding-3-small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_c4b4e_row3_col0\" class=\"data row3 col0\" >Status</td>\n",
       "      <td id=\"T_c4b4e_row3_col1\" class=\"data row3 col1\" >‚úÖ Created</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3ff396a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = memory.create_store(\n",
    "    name=MEMORY_STORE_NAME,\n",
    "    chat_model=LOCAL_CHAT,\n",
    "    embedding_model=EMBEDDING,\n",
    "    description=\"Space exploration preferences and conversation history\",\n",
    "    user_profile_details=\"Favorite planets, space missions, exploration interests, celestial phenomena preferences\"\n",
    ")\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_store_created(MEMORY_STORE_NAME, LOCAL_CHAT, EMBEDDING)\n",
    "else:\n",
    "    show_error(result['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9c97e1",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 2: Store User Memories\n",
    "\n",
    "Extract and store memories from conversations using the Memory API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f38ab17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| User | Scope ID | Profile |\n",
       "|------|----------|---------|\n",
       "| Alice | `user_alice_123` | Loves Mars, interested in rover missions, wants to see the northern lights |\n",
       "| Bob | `user_bob_456` | Saturn fan, fascinated by rings and moons, dreams of Europa exploration |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test users with different space exploration profiles\n",
    "USER_ALICE = \"user_alice_123\"\n",
    "USER_BOB = \"user_bob_456\"\n",
    "\n",
    "display(Markdown('''\n",
    "| User | Scope ID | Profile |\n",
    "|------|----------|---------|\n",
    "| Alice | `user_alice_123` | Loves Mars, interested in rover missions, wants to see the northern lights |\n",
    "| Bob | `user_bob_456` | Saturn fan, fascinated by rings and moons, dreams of Europa exploration |\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcbe7892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Processing Alice's memories...\n",
      "‚úÖ Alice's Memories Stored - No new memories extracted\n"
     ]
    }
   ],
   "source": [
    "# Store Alice's preferences\n",
    "alice_msgs = build_conversation(\n",
    "    \"Mars is my absolute favorite planet! I'm fascinated by the Perseverance rover and Ingenuity helicopter missions. I also really want to see the northern lights on Earth someday - they're on my bucket list.\",\n",
    "    \"Got it! Mars is your favorite, you love the rover missions, and you're dreaming of seeing the aurora borealis. I'll remember that!\"\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Processing Alice's memories...\")\n",
    "result = memory.update_memories(MEMORY_STORE_NAME, USER_ALICE, alice_msgs)\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_memories(\"Alice's Memories Stored\", result.get('memories', []))\n",
    "else:\n",
    "    show_error(result['error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99ec45c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Processing Bob's memories...\n",
      "‚úÖ Bob's Memories Stored - No new memories extracted\n"
     ]
    }
   ],
   "source": [
    "# Store Bob's preferences\n",
    "bob_msgs = build_conversation(\n",
    "    \"Saturn is definitely my favorite - those rings are just spectacular! I'm really interested in its moon Europa and the possibility of life in its subsurface ocean. I also love following the James Webb telescope discoveries.\",\n",
    "    \"Saturn fan with a love for those iconic rings! You're curious about Europa's ocean and following JWST discoveries. Got it!\"\n",
    ")\n",
    "\n",
    "print(\"‚è≥ Processing Bob's memories...\")\n",
    "result = memory.update_memories(MEMORY_STORE_NAME, USER_BOB, bob_msgs)\n",
    "\n",
    "if 'error' not in result:\n",
    "    show_memories(\"Bob's Memories Stored\", result.get('memories', []))\n",
    "else:\n",
    "    show_error(result['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dcd8de",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 3: Search Memories (Scope Isolation)\n",
    "\n",
    "Verify each user only sees their own memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb0552ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Query:** \"Which planet should I learn more about?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üë© Alice's Memories"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_618e8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_618e8_level0_col0\" class=\"col_heading level0 col0\" >Type</th>\n",
       "      <th id=\"T_618e8_level0_col1\" class=\"col_heading level0 col1\" >Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_618e8_row0_col0\" class=\"data row0 col0\" >user_profile</td>\n",
       "      <td id=\"T_618e8_row0_col1\" class=\"data row0 col1\" >User is fascinated by Mars rover missions, especially Perseverance and Ingenuity.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_618e8_row1_col0\" class=\"data row1 col0\" >user_profile</td>\n",
       "      <td id=\"T_618e8_row1_col1\" class=\"data row1 col1\" >User's favorite planet is Mars.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_618e8_row2_col0\" class=\"data row2 col0\" >user_profile</td>\n",
       "      <td id=\"T_618e8_row2_col1\" class=\"data row2 col1\" >User has a bucket list goal to see the northern lights (aurora borealis) on Earth.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3fe38190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### üë® Bob's Memories"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1c79e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_1c79e_level0_col0\" class=\"col_heading level0 col0\" >Type</th>\n",
       "      <th id=\"T_1c79e_level0_col1\" class=\"col_heading level0 col1\" >Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_1c79e_row0_col0\" class=\"data row0 col0\" >user_profile</td>\n",
       "      <td id=\"T_1c79e_row0_col1\" class=\"data row0 col1\" >User's favorite planet is Saturn, with a special appreciation for its rings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1c79e_row1_col0\" class=\"data row1 col0\" >user_profile</td>\n",
       "      <td id=\"T_1c79e_row1_col1\" class=\"data row1 col1\" >User follows discoveries from the James Webb Space Telescope (JWST).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_1c79e_row2_col0\" class=\"data row2 col0\" >user_profile</td>\n",
       "      <td id=\"T_1c79e_row2_col1\" class=\"data row2 col1\" >User is interested in Europa's subsurface ocean and the potential for extraterrestrial life there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3fe38050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "‚úÖ **Scope isolation verified** - each user sees only their own memories"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Which planet should I learn more about?\"\n",
    "display(Markdown(f'**Query:** \"{query}\"'))\n",
    "\n",
    "# Each user only sees their own memories\n",
    "alice_result = memory.search_memories(MEMORY_STORE_NAME, USER_ALICE, query)\n",
    "bob_result = memory.search_memories(MEMORY_STORE_NAME, USER_BOB, query)\n",
    "\n",
    "show_search_results(\"Alice\", \"üë©\", alice_result.get('memories', []))\n",
    "show_search_results(\"Bob\", \"üë®\", bob_result.get('memories', []))\n",
    "\n",
    "display(Markdown('‚úÖ **Scope isolation verified** - each user sees only their own memories'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a474a9",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 4: Agent with Memory\n",
    "\n",
    "Create an agent that uses `memory_search` tool.\n",
    "\n",
    "> ‚ö†Ô∏è **Current Limitation**: The `memory_search` tool is **not supported with BYO (gateway) models**.\n",
    "> Error: `\"The following tools are not supported with BYO model: memory_search. Please remove these tools or use a standard model deployment.\"`\n",
    "> \n",
    "> **Workaround**: Use a local model deployment for agents with memory tools.\n",
    "> Once this limitation is lifted, you can switch back to gateway models (`connection/model` format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f63eb335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Agents Created\n",
       "| User | Agent Version | Memory Scope |\n",
       "|------|--------------|--------------|\n",
       "| Alice | `4` | `user_alice_123` |\n",
       "| Bob | `5` | `user_bob_456` |\n",
       "\n",
       "> ‚ö†Ô∏è Using local model (gateway not supported with `memory_search`)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "AGENT_NAME = \"SpaceExpert\"\n",
    "\n",
    "def create_agent_for_user(scope: str) -> tuple:\n",
    "    \"\"\"Create an agent scoped to a specific user.\"\"\"\n",
    "    agent = project_client.agents.create_version(\n",
    "        agent_name=AGENT_NAME,\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=LOCAL_CHAT,\n",
    "            instructions=\"You are a friendly space exploration expert. Personalize recommendations based on user's favorite planets and space interests. Remember their specific interests in missions, phenomena, and celestial bodies. Always use the memory tool before giving an answer.\",\n",
    "            tools=[{\n",
    "                \"type\": \"memory_search\",\n",
    "                \"memory_store_name\": MEMORY_STORE_NAME,\n",
    "                \"scope\": scope,\n",
    "                \"update_delay\": 1\n",
    "            }]\n",
    "        )\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "# Create agents for each user\n",
    "agent_alice = create_agent_for_user(USER_ALICE)\n",
    "agent_bob = create_agent_for_user(USER_BOB)\n",
    "\n",
    "display(Markdown('''\n",
    "### Agents Created\n",
    "| User | Agent Version | Memory Scope |\n",
    "|------|--------------|--------------|\n",
    "| Alice | `''' + agent_alice.version + '''` | `user_alice_123` |\n",
    "| Bob | `''' + agent_bob.version + '''` | `user_bob_456` |\n",
    "\n",
    "> ‚ö†Ô∏è Using local model (gateway not supported with `memory_search`)\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3285087e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Query:** \"Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üë© Alice's Recommendation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5f471_row0_col0, #T_5f471_row0_col1, #T_5f471_row1_col0, #T_5f471_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5f471\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5f471_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_5f471_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5f471_row0_col0\" class=\"data row0 col0\" >üë§ User</td>\n",
       "      <td id=\"T_5f471_row0_col1\" class=\"data row0 col1\" >Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5f471_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_5f471_row1_col1\" class=\"data row1 col1\" >Since you love Mars and are fascinated by the Perseverance rover and Ingenuity helicopter, here‚Äôs a fascinating space fact combining exploration and a space phenomenon!\n",
       "\n",
       "Did you know that NASA‚Äôs Perseverance rover is studying not only the Martian surface but also the planet‚Äôs thin atmosphere to better understand how Mars lost most of its air? One particularly cool fact is that Mars experiences its own kind of auroras, called \"aurora australis\" in the southern hemisphere and \"aurora borealis\" in the northern hemisphere of Mars! These Martian auroras are caused by solar particles interacting with the planet‚Äôs atmosphere, but unlike Earth‚Äôs bright and colorful northern lights, Martian auroras glow mostly in ultraviolet light and are invisible to the naked eye.\n",
       "\n",
       "So, while you dream of seeing northern lights here on Earth, Mars has its own invisible auroras ‚Äî a fascinating phenomenon that links your favorite planet and your celestial bucket list!\n",
       "\n",
       "Would you like to hear more about the latest discoveries from Perseverance or how Ingenuity‚Äôs flights are helping pave the way for future Mars exploration?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3f25c550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### üë® Bob's Recommendation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_eff47_row0_col0, #T_eff47_row0_col1, #T_eff47_row1_col0, #T_eff47_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_eff47\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_eff47_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_eff47_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_eff47_row0_col0\" class=\"data row0 col0\" >üë§ User</td>\n",
       "      <td id=\"T_eff47_row0_col1\" class=\"data row0 col1\" >Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_eff47_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_eff47_row1_col1\" class=\"data row1 col1\" >Since you love Saturn and its rings, and you're intrigued by Europa's subsurface ocean and the search for life, I have a fascinating connection for you! While Europa is actually a moon of Jupiter, not Saturn, its icy shell and subsurface ocean are among the most promising places to look for life beyond Earth. Scientists are using data from telescopes like the James Webb Space Telescope (JWST) to study the surfaces and atmospheres of these icy moons in unprecedented detail.\n",
       "\n",
       "A fascinating fact: JWST's powerful infrared instruments can analyze the chemical composition of Europa‚Äôs surface and plumes, helping us search for signs of organic molecules that might hint at life. Combining this with what we know about Saturn‚Äôs rings‚Äîcomposed primarily of water ice with some organic compounds‚Äîgives us a greater understanding of how icy worlds and their environments might support life or reveal clues about the early solar system.\n",
       "\n",
       "Would you like me to share the latest JWST discoveries about Europa or the detailed structure of Saturn‚Äôs rings?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3f25c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### ‚úÖ Same query, different answers!\n",
       "- **Alice** gets Mars/rover mission recommendations (loves Mars and Perseverance)\n",
       "- **Bob** gets Saturn/Europa recommendations (fascinated by rings and subsurface oceans)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Hi! I want to learn something fascinating about space today. What would you recommend based on my interests?\"\n",
    "display(Markdown(f'**Query:** \"{query}\"'))\n",
    "\n",
    "# Alice's recommendation\n",
    "response_alice = openai_client.responses.create(\n",
    "    input=query,\n",
    "    extra_body={\"agent\": {\"name\": agent_alice.name, \"version\": agent_alice.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "alice_response = response_alice.output_text if hasattr(response_alice, 'output_text') else str(response_alice.output)\n",
    "\n",
    "# Bob's recommendation\n",
    "response_bob = openai_client.responses.create(\n",
    "    input=query,\n",
    "    extra_body={\"agent\": {\"name\": agent_bob.name, \"version\": agent_bob.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "bob_response = response_bob.output_text if hasattr(response_bob, 'output_text') else str(response_bob.output)\n",
    "\n",
    "display(Markdown('---'))\n",
    "show_conversation(\"üë© Alice's Recommendation\", query, alice_response)\n",
    "display(Markdown('---'))\n",
    "show_conversation(\"üë® Bob's Recommendation\", query, bob_response)\n",
    "\n",
    "display(Markdown('''\n",
    "### ‚úÖ Same query, different answers!\n",
    "- **Alice** gets Mars/rover mission recommendations (loves Mars and Perseverance)\n",
    "- **Bob** gets Saturn/Europa recommendations (fascinated by rings and subsurface oceans)\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47aa57f",
   "metadata": {},
   "source": [
    "---\n",
    "# Scenario 5: Automatic Memory Extraction\n",
    "\n",
    "Demonstrate that the agent **automatically learns** from conversations - no manual `update_memories()` needed!\n",
    "\n",
    "> üìù **How it works:**\n",
    "> - The `memory_search` tool has `update_delay` set (we use 1 second for demo)\n",
    "> - After each response, the system automatically extracts memories\n",
    "> - Chat summaries are enabled in our memory store (`chat_summary_enabled: True`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "834abbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_CHARLIE = \"user_charlie_789\"\n",
    "agent_charlie = create_agent_for_user(USER_CHARLIE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa634cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Turn 1: Charlie chats with the agent"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Charlie's First Message"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d8ea9_row0_col0, #T_d8ea9_row0_col1, #T_d8ea9_row1_col0, #T_d8ea9_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d8ea9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d8ea9_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_d8ea9_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d8ea9_row0_col0\" class=\"data row0 col0\" >üë§ Charlie</td>\n",
       "      <td id=\"T_d8ea9_row0_col1\" class=\"data row0 col1\" >Hi! I'm really excited about the upcoming solar eclipse next month. I want to find the best viewing spot and learn about what causes them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d8ea9_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_d8ea9_row1_col1\" class=\"data row1 col1\" >Hi! It‚Äôs awesome that you‚Äôre excited about the solar eclipse next month. Solar eclipses happen when the Moon passes between the Earth and the Sun, blocking the Sun‚Äôs light either partially or totally in some areas. This alignment causes the beautiful and rare phenomenon where the sky darkens during the day.\n",
       "\n",
       "For the best viewing spot, it depends on the path of the eclipse‚Äôs shadow, called the path of totality for a total eclipse. Locations inside this path will experience the full eclipse. You can check online maps specific to the upcoming eclipse to find cities or areas that lie in the path of totality. Usually, places with clear skies and minimal light pollution are ideal, like rural areas or open fields.\n",
       "\n",
       "If you tell me your location or the region you plan to travel to, I can help you find the perfect viewing spot! Would you also like some safety tips for viewing the eclipse?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3f25c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Charlie's Second Message"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_861e9_row0_col0, #T_861e9_row0_col1, #T_861e9_row1_col0, #T_861e9_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_861e9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_861e9_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_861e9_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_861e9_row0_col0\" class=\"data row0 col0\" >üë§ Charlie</td>\n",
       "      <td id=\"T_861e9_row0_col1\" class=\"data row0 col1\" >That sounds great! By the way, Jupiter is my favorite planet. I love learning about the Great Red Spot and the Galilean moons.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_861e9_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_861e9_row1_col1\" class=\"data row1 col1\" >Jupiter is an incredible favorite! The Great Red Spot is a fascinating giant storm that's been raging for centuries, and the Galilean moons‚ÄîIo, Europa, Ganymede, and Callisto‚Äîare some of the most intriguing worlds in our solar system, each with unique characteristics like volcanic activity on Io and the potential subsurface ocean on Europa. If you're interested, I can share more about ongoing missions like Juno exploring Jupiter's atmosphere or upcoming plans to study its moons in greater detail! Would you like to dive deeper into any of these topics?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3f25c410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('### Turn 1: Charlie chats with the agent'))\n",
    "\n",
    "charlie_msg1 = \"Hi! I'm really excited about the upcoming solar eclipse next month. I want to find the best viewing spot and learn about what causes them.\"\n",
    "\n",
    "response1 = openai_client.responses.create(\n",
    "    input=charlie_msg1,\n",
    "    extra_body={\"agent\": {\"name\": agent_charlie.name, \"version\": agent_charlie.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "charlie_response1 = response1.output_text if hasattr(response1, 'output_text') else str(response1.output)\n",
    "\n",
    "show_conversation(\"Charlie's First Message\", charlie_msg1, charlie_response1, \"Charlie\")\n",
    "\n",
    "# Continue the conversation\n",
    "charlie_msg2 = \"That sounds great! By the way, Jupiter is my favorite planet. I love learning about the Great Red Spot and the Galilean moons.\"\n",
    "\n",
    "response2 = openai_client.responses.create(\n",
    "    input=charlie_msg2,\n",
    "    extra_body={\"agent\": {\"name\": agent_charlie.name, \"version\": agent_charlie.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "charlie_response2 = response2.output_text if hasattr(response2, 'output_text') else str(response2.output)\n",
    "\n",
    "display(Markdown('---'))\n",
    "show_conversation(\"Charlie's Second Message\", charlie_msg2, charlie_response2, \"Charlie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e9b8965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory extraction should be complete\n"
     ]
    }
   ],
   "source": [
    "# Wait for automatic memory extraction\n",
    "display(Markdown('### ‚è≥ Waiting for automatic memory extraction...'))\n",
    "display(Markdown('> The `memory_search` tool automatically extracts and stores memories after `update_delay` seconds of inactivity.'))\n",
    "\n",
    "import time\n",
    "for i in range(30, 0, -10):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(f'### ‚è≥ Waiting for memory extraction... {i}s'))\n",
    "    time.sleep(10)\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(\"‚úÖ Memory extraction should be complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94d1846e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Turn 2: New conversation - test if agent remembers"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Charlie Asks About Previous Chat"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5acf1_row0_col0, #T_5acf1_row0_col1, #T_5acf1_row1_col0, #T_5acf1_row1_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5acf1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5acf1_level0_col0\" class=\"col_heading level0 col0\" >Role</th>\n",
       "      <th id=\"T_5acf1_level0_col1\" class=\"col_heading level0 col1\" >Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5acf1_row0_col0\" class=\"data row0 col0\" >üë§ Charlie</td>\n",
       "      <td id=\"T_5acf1_row0_col1\" class=\"data row0 col1\" >What have we recently been talking about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5acf1_row1_col0\" class=\"data row1 col0\" >ü§ñ Agent</td>\n",
       "      <td id=\"T_5acf1_row1_col1\" class=\"data row1 col1\" >Recently, we've been talking about your favorite planet Jupiter, focusing on the Great Red Spot and the fascinating Galilean moons‚ÄîIo, Europa, Ganymede, and Callisto. You‚Äôre especially interested in unique features like Io‚Äôs volcanic activity and Europa‚Äôs potential subsurface ocean. We also discussed ongoing missions like Juno that study Jupiter‚Äôs atmosphere, as well as upcoming plans to explore its moons.\n",
       "\n",
       "In addition, you expressed excitement about the solar eclipse happening in February 2026. You wanted to understand how solar eclipses occur and find the best spots to view the eclipse safely.\n",
       "\n",
       "Would you like me to share the latest updates on Jupiter missions or offer tailored recommendations for the eclipse viewing?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xffff3f25d590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### ‚úÖ Automatic Memory Extraction Works!\n",
       "\n",
       "**What just happened:**\n",
       "1. Charlie chatted about solar eclipses & Jupiter being their favorite planet\n",
       "2. We did **NOT** call `update_memories()` manually\n",
       "3. The `memory_search` tool automatically extracted and stored the conversation\n",
       "4. In a new conversation, the agent remembers what we discussed!\n",
       "\n",
       "**This is the magic of the `memory_search` tool** - it handles extraction automatically.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Turn 2: New conversation - ask what we talked about\n",
    "display(Markdown('### Turn 2: New conversation - test if agent remembers'))\n",
    "\n",
    "charlie_msg3 = \"What have we recently been talking about?\"\n",
    "\n",
    "response3 = openai_client.responses.create(\n",
    "    input=charlie_msg3,\n",
    "    extra_body={\"agent\": {\"name\": agent_charlie.name, \"version\": agent_charlie.version, \"type\": \"agent_reference\"}}\n",
    ")\n",
    "charlie_response3 = response3.output_text if hasattr(response3, 'output_text') else str(response3.output)\n",
    "\n",
    "show_conversation(\"Charlie Asks About Previous Chat\", charlie_msg3, charlie_response3, \"Charlie\")\n",
    "\n",
    "display(Markdown('''\n",
    "### ‚úÖ Automatic Memory Extraction Works!\n",
    "\n",
    "**What just happened:**\n",
    "1. Charlie chatted about solar eclipses & Jupiter being their favorite planet\n",
    "2. We did **NOT** call `update_memories()` manually\n",
    "3. The `memory_search` tool automatically extracted and stored the conversation\n",
    "4. In a new conversation, the agent remembers what we discussed!\n",
    "\n",
    "**This is the magic of the `memory_search` tool** - it handles extraction automatically.\n",
    "'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86101d7",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "## Key Learnings\n",
    "\n",
    "| Concept | Detail |\n",
    "|---------|--------|\n",
    "| Memory API Models | Must be deployed **locally** (not via gateway) |\n",
    "| Agent with `memory_search` | Also requires local model |\n",
    "| Token Audience | `https://ai.azure.com` |\n",
    "| Responses API | `openai_client.responses.create()` with `agent_reference` |\n",
    "\n",
    "## Current Limitation\n",
    "\n",
    "> ‚ö†Ô∏è **`memory_search` tool does not support BYO (gateway) models**\n",
    "> \n",
    "> Error: `\"The following tools are not supported with BYO model: memory_search\"`\n",
    "\n",
    "## Files\n",
    "\n",
    "| File | Purpose |\n",
    "|------|---------|\n",
    "| `memory_helpers.py` | `MemoryClient` class, `build_conversation()` |\n",
    "| `display_helpers.py` | Display functions for tables and results |\n",
    "| `spoke.bicep` | Infrastructure (local models + APIM connection) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9e29048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete all resources\n",
    "# !az group delete -n \"{RG}\" --yes --no-wait\n",
    "# print(f\"üóëÔ∏è Deleting resource group: {RG}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
